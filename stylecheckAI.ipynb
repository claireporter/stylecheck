{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/claireporter/stylecheck/blob/main/stylecheckAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **INPUT REQUIRED**\n",
        "\n",
        "###1) Set up your Open AI key under Secrets in colab\n",
        "\n",
        "\n",
        "*   Name: OPENAI_API_KEY\n",
        "*   Value: Value from Open AI:\n",
        "(Get from https://platform.openai.com/settings/organization/api-keys)\n",
        "\n",
        "###2) Set up a free Pinecone account\n",
        "\n",
        "####3) Set up your Pinecone API Key under Secrets in colab\n",
        "\n",
        "\n",
        "*   Name PINECONE_API_KEY\n",
        "*   Value from Pinecone:\n",
        "(Set up under API Keys from https://app.pinecone.io/)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "d5coieAiVzLv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Irish Examiner Style Guide Check using Open AI and Pinecone\n",
        "\n",
        "## Import libraries"
      ],
      "metadata": {
        "id": "SyjBPkcjeobr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28\n",
        "# tiktoken only needed for cost evaluation, not actual runnind of the model on the article\n",
        "!pip install tiktoken\n",
        "!pip install -qU \\\n",
        "    pinecone-client==3.0.2 \\\n",
        "    openai==0.28.0\n",
        "\n",
        "import openai\n",
        "import json\n",
        "import os\n",
        "\n",
        "# time only needed for speed evaluation\n",
        "import time\n",
        "# tiktoken only needed for cost evaluation, not actual running of the model on the article\n",
        "import tiktoken\n",
        "# reading google sheet file\n",
        "import pandas as pd\n",
        "\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "from google.colab import drive, userdata\n",
        "\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "openai.api_key = api_key\n",
        "\n",
        "## Used for form in google colab\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# Add in the data file\n",
        "if not os.path.exists('data'):\n",
        "    os.makedirs('data')\n",
        "\n",
        "# Download the Style Guide directly from the GitHub raw URL\n",
        "file_url = \"https://raw.githubusercontent.com/claireporter/stylecheck/main/Style_Guide.xlsx\"\n",
        "destination_path = \"data/Style_Guide.xlsx\"\n",
        "!wget -O {destination_path} {file_url}\n",
        "\n"
      ],
      "metadata": {
        "id": "qXNyxmRT6yB4",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 905
        },
        "outputId": "b5f989ef-dc65-4e27-e68f-e4d462da9ded"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.12/dist-packages (from openai==0.28) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from openai==0.28) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from openai==0.28) (3.12.15)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->openai==0.28) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->openai==0.28) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->openai==0.28) (2025.8.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (1.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->openai==0.28) (4.15.0)\n",
            "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.106.1\n",
            "    Uninstalling openai-1.106.1:\n",
            "      Successfully uninstalled openai-1.106.1\n",
            "Successfully installed openai-0.28.0\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (0.11.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (2025.8.3)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "error",
          "ename": "TimeoutException",
          "evalue": "Requesting secret OPENAI_API_KEY timed out. Secrets can only be fetched when running from the Colab UI.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2534640515.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'OPENAI_API_KEY'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mopenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/userdata.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m     64\u001b[0m     )\n\u001b[1;32m     65\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exists'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mSecretNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTimeoutException\u001b[0m: Requesting secret OPENAI_API_KEY timed out. Secrets can only be fetched when running from the Colab UI."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wTYZccq4enaV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Access the Style_Guide\n",
        "\n",
        "(sample of 10 rules)\n",
        "\n"
      ],
      "metadata": {
        "id": "jKA-5wyp46xx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add in the data file\n",
        "if not os.path.exists('data'):\n",
        "    os.makedirs('data')\n",
        "\n",
        "# Step 2: Download the file directly from the GitHub raw URL\n",
        "file_url = \"https://raw.githubusercontent.com/claireporter/stylecheck/main/Style_Guide.xlsx\"\n",
        "destination_path = \"data/Style_Guide.xlsx\"\n",
        "\n",
        "# Use wget to download the file\n",
        "!wget -O {destination_path} {file_url}\n",
        "\n",
        "print(f\"File has been downloaded to: {destination_path}\")"
      ],
      "metadata": {
        "id": "EGLZ4ypr02QZ",
        "outputId": "04270c92-b68b-42c8-9fc0-829cb29b6b61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-15 13:50:56--  https://raw.githubusercontent.com/claireporter/stylecheck/main/Style_Guide.xlsx\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11877 (12K) [application/octet-stream]\n",
            "Saving to: ‘data/Style_Guide.xlsx’\n",
            "\n",
            "\rdata/Style_Guide.xl   0%[                    ]       0  --.-KB/s               \rdata/Style_Guide.xl 100%[===================>]  11.60K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-01-15 13:50:56 (96.9 MB/s) - ‘data/Style_Guide.xlsx’ saved [11877/11877]\n",
            "\n",
            "File has been downloaded to: data/Style_Guide.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xlsx_file_path = \"/content/data/Style_Guide.xlsx\" # Update xlsx_file_path with downloaded file\n",
        "df = pd.read_excel(xlsx_file_path, sheet_name=\"Data Sheet\")\n"
      ],
      "metadata": {
        "id": "optvOhBq4k1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **INPUT OPTIONAL**\n",
        "## Adjust costs - costs below are for 2024 and depending on product plans, region"
      ],
      "metadata": {
        "id": "q8CZ1OYnOP_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Open AI Costs - Adjust according to open ai model pricing\n",
        "\n",
        "# Embedding model cost - text_embedding_3_large\n",
        "text_embedding_3_large_tokens_cost_per_million = 0.13\n",
        "#  Gen AI cost -  gpt-4o-mini\n",
        "gpt4o_mini_input_tokens_cost_per_million =  0.150 # ($s)\n",
        "gpt4o_mini_output_tokens_cost_per_million = 0.6 # ($s)\n",
        "\n",
        "# Pinecone costs - currently using free plan, but these are miniumum prices for the Standard plan\n",
        "\n",
        "# Price per GB - Adjust based on your pricing region\n",
        "storage_cost_per_gb = 0.33\n",
        "# Pinecone pricing for read units - adjust according to pinecone plan\n",
        "read_cost_per_million = 16\n",
        "# Pinecone pricing for write units - adjust according to pinecone plan\n",
        "write_cost_per_million = 4\n"
      ],
      "metadata": {
        "id": "niIWW_kODuhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculate costs"
      ],
      "metadata": {
        "id": "Gs5AqMSi6v-r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUikxl3sECHY"
      },
      "outputs": [],
      "source": [
        "# Calculate Pinecone cost\n",
        "def calculate_pinecone_cost(read_units, write_units, storage_cost_per_gb, vector_size_in_bytes, num_vectors):\n",
        "    # Calculate storage cost\n",
        "    storage_cost = (num_vectors * vector_size_in_bytes) / 1e9 * storage_cost_per_gb\n",
        "\n",
        "    # Costs for read and write units\n",
        "    read_cost_per_unit = read_cost_per_million/1_000_000\n",
        "    write_cost_per_unit = write_cost_per_million/1_000_000\n",
        "    total_cost = (read_units * read_cost_per_unit) + (write_units * write_cost_per_unit) + storage_cost\n",
        "\n",
        "    return total_cost\n",
        "\n",
        "def calculate_token_usage_cost(tokens, cost_per_million):\n",
        "     cost_per_one_token = cost_per_million / 1000000\n",
        "     return (tokens * cost_per_one_token)\n",
        "\n",
        "def get_token_costs(model):\n",
        "\n",
        "    input_tokens_cost_per_million = gpt4o_mini_input_tokens_cost_per_million\n",
        "    output_tokens_cost_per_million = gpt4o_mini_output_tokens_cost_per_million\n",
        "    return input_tokens_cost_per_million, output_tokens_cost_per_million"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-PYtMMjY1g_1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **INPUT REQUIRED**\n",
        "#### Allow access to Google Drive\n",
        "#### **INPUT REQUIRED**\n",
        "#### Set up Pinecone\n",
        "#### Save PCapi.txt file to drive to connect to Pinecone"
      ],
      "metadata": {
        "id": "gN3E3PQMIrKa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connect to pinecone\n"
      ],
      "metadata": {
        "id": "J5eZDpRcqwk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pinecone\n",
        "\n",
        "# Access the Pinecone API key from Colab secrets\n",
        "PCApi = userdata.get('PINECONE_API_KEY')\n",
        "\n",
        "if not PCApi:\n",
        "    raise ValueError(\"PINECONE_API_KEY is not set in the environment variables.\")"
      ],
      "metadata": {
        "id": "V2SEXMWK6GkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# View the structure of the style_guide.xlsx file"
      ],
      "metadata": {
        "id": "i8UvslniRHE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets view the structure of the guidelines\n",
        "\n",
        "# Select specific columns and rename them\n",
        "df_subset = df[['ID', 'Style Point', 'Our Style', 'Correct usage', 'Incorrect usage', 'Keywords', 'Type', 'Replace']].head(7)\n",
        "df_subset = df_subset.rename(columns={\n",
        "    'Style Point': 'Style Point (Style Name)',\n",
        "    'Our Style': 'Our Style (Style Description)'\n",
        "})\n",
        "df_subset = df_subset.fillna(\"\")\n",
        "# Display the result\n",
        "df_subset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "VmlJf_dZ2t3b",
        "outputId": "f827757b-b5c0-4e20-ef44-0d33d2bcb619"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   ID  Style Point (Style Name)  \\\n",
              "0   5    aborigines, Aborigines   \n",
              "1   6                    am, pm   \n",
              "2   7      Absence, absenteeism   \n",
              "3   8                 All right   \n",
              "4  11                   adapter   \n",
              "5  18                 Age, ages   \n",
              "6  26  Athletics race distances   \n",
              "\n",
              "                       Our Style (Style Description)  \\\n",
              "0  Use aborigines when referring to indigenous po...   \n",
              "1  Both lower case when referring to time. Snug u...   \n",
              "2  **Absence** is not the same as **absenteeism**...   \n",
              "3  Use 'all right'  unless in informal speech or ...   \n",
              "4  An adapter is somebody who adapts; it is not a...   \n",
              "5  We do not use hyphens when the age follows the...   \n",
              "6  Races under 2,000m are usually described as 't...   \n",
              "\n",
              "                                       Correct usage  \\\n",
              "0  The indigenous peoples of Taiwan, or Taiwan ab...   \n",
              "1             The newspaper goes to press at 10.30pm   \n",
              "2  Absence makes the heart grow fonder.\\n \\n \\n T...   \n",
              "3                   Using alright was not all right.   \n",
              "4         She was an early adapter of the technology   \n",
              "5  The accident happened when she was 10 years ol...   \n",
              "6  People run the 1500m but take part in a 5,000m...   \n",
              "\n",
              "                                     Incorrect usage  \\\n",
              "0  Taiwan’s Aborigines have lived on the island f...   \n",
              "1            The newspaper goes to press at 10:30 PM   \n",
              "2  Half the staff caught covid leading to a high ...   \n",
              "3                                     She is alright   \n",
              "4         She was an early adaptor of the technology   \n",
              "5  The accident happened when she was 10-years-ol...   \n",
              "6                              People run the 1,500m   \n",
              "\n",
              "                                         Keywords  Type Replace  \n",
              "0               indigenous, aborigine, aborigines     2          \n",
              "1                                      Irrelevant     4          \n",
              "2                            absence, absenteeism     2          \n",
              "3                              all right, alright     2          \n",
              "4  adapter, adaptor, adopt, adapt, adopts, adapts     2          \n",
              "5                                      Irrelevant     3          \n",
              "6                                      Irrelevant     3          "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4c7dfbed-1900-4739-8400-791dae8427f1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Style Point (Style Name)</th>\n",
              "      <th>Our Style (Style Description)</th>\n",
              "      <th>Correct usage</th>\n",
              "      <th>Incorrect usage</th>\n",
              "      <th>Keywords</th>\n",
              "      <th>Type</th>\n",
              "      <th>Replace</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>aborigines, Aborigines</td>\n",
              "      <td>Use aborigines when referring to indigenous po...</td>\n",
              "      <td>The indigenous peoples of Taiwan, or Taiwan ab...</td>\n",
              "      <td>Taiwan’s Aborigines have lived on the island f...</td>\n",
              "      <td>indigenous, aborigine, aborigines</td>\n",
              "      <td>2</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6</td>\n",
              "      <td>am, pm</td>\n",
              "      <td>Both lower case when referring to time. Snug u...</td>\n",
              "      <td>The newspaper goes to press at 10.30pm</td>\n",
              "      <td>The newspaper goes to press at 10:30 PM</td>\n",
              "      <td>Irrelevant</td>\n",
              "      <td>4</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7</td>\n",
              "      <td>Absence, absenteeism</td>\n",
              "      <td>**Absence** is not the same as **absenteeism**...</td>\n",
              "      <td>Absence makes the heart grow fonder.\\n \\n \\n T...</td>\n",
              "      <td>Half the staff caught covid leading to a high ...</td>\n",
              "      <td>absence, absenteeism</td>\n",
              "      <td>2</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8</td>\n",
              "      <td>All right</td>\n",
              "      <td>Use 'all right'  unless in informal speech or ...</td>\n",
              "      <td>Using alright was not all right.</td>\n",
              "      <td>She is alright</td>\n",
              "      <td>all right, alright</td>\n",
              "      <td>2</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>adapter</td>\n",
              "      <td>An adapter is somebody who adapts; it is not a...</td>\n",
              "      <td>She was an early adapter of the technology</td>\n",
              "      <td>She was an early adaptor of the technology</td>\n",
              "      <td>adapter, adaptor, adopt, adapt, adopts, adapts</td>\n",
              "      <td>2</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>18</td>\n",
              "      <td>Age, ages</td>\n",
              "      <td>We do not use hyphens when the age follows the...</td>\n",
              "      <td>The accident happened when she was 10 years ol...</td>\n",
              "      <td>The accident happened when she was 10-years-ol...</td>\n",
              "      <td>Irrelevant</td>\n",
              "      <td>3</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>26</td>\n",
              "      <td>Athletics race distances</td>\n",
              "      <td>Races under 2,000m are usually described as 't...</td>\n",
              "      <td>People run the 1500m but take part in a 5,000m...</td>\n",
              "      <td>People run the 1,500m</td>\n",
              "      <td>Irrelevant</td>\n",
              "      <td>3</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4c7dfbed-1900-4739-8400-791dae8427f1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4c7dfbed-1900-4739-8400-791dae8427f1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4c7dfbed-1900-4739-8400-791dae8427f1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2ed9c299-9489-4efc-8a42-506a0546f0e6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2ed9c299-9489-4efc-8a42-506a0546f0e6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2ed9c299-9489-4efc-8a42-506a0546f0e6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_d758139d-8b2e-45ef-be13-544deded6370\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_subset')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d758139d-8b2e-45ef-be13-544deded6370 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_subset');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_subset",
              "summary": "{\n  \"name\": \"df_subset\",\n  \"rows\": 7,\n  \"fields\": [\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7,\n        \"min\": 5,\n        \"max\": 26,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          5,\n          6,\n          18\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Style Point (Style Name)\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"aborigines, Aborigines\",\n          \"am, pm\",\n          \"Age, ages\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Our Style (Style Description)\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Use aborigines when referring to indigenous populations, though our preference is for **indigenous peoples** . \\n \\n \\n Use Aborigines when referring to the indigenous peoples of Australia.\",\n          \"Both lower case when referring to time. Snug up against the number\",\n          \"We do not use hyphens when the age follows the noun (**The boy was two years old**).\\n \\n \\n We use hyphens when the age precedes the noun, ie when it\\u2019s an adjectival compound. (**The two-year-old boy)** \\n \\n \\n Normal numbers style applies \\u2013 we use words for numbers **one to nine** and digits for the number **10** onwards.\\n \\n \\n When writing about a group of people whose ages you need to give, our style is to hyphenate the first digit, and write year-olds after the last age to refer to all previously listed ages. - eg **16- to 29-year-olds.**\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Correct usage\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"The indigenous peoples of Taiwan, or Taiwan aborigines, make up about 560,000 people.\",\n          \"The newspaper goes to press at 10.30pm\",\n          \"The accident happened when she was 10 years old.\\n \\n \\n The 10-year-old girl fell and hurt herself.\\n \\n \\n She was two and a half months old when she was fostered.\\n \\n \\n She was fostered as a two-and-a-half-month-old baby.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Incorrect usage\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Taiwan\\u2019s Aborigines have lived on the island for thousands of years.\",\n          \"The newspaper goes to press at 10:30 PM\",\n          \"The accident happened when she was 10-years-old.\\n \\n \\n The 10 year old girl fell and hurt herself.\\n \\n \\n She was two-and-a-half-months old when she was fostered.\\n \\n \\n She was fostered as a two and a half month-old baby.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Keywords\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Irrelevant\",\n          \"adapter, adaptor, adopt, adapt, adopts, adapts\",\n          \"absence, absenteeism\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Type\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2,\n        \"max\": 4,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2,\n          4,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Replace\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Ec_QfjUP7Kjj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### The Type of guideline defines how we identify it\n",
        "\n",
        "1 - is a simple search / replace - could be done without AI (Search for Keywords; suggested replacement from 'Replace' column\n",
        "\n",
        "2 - search using Keywords (checking each item in comma-delimited list) (not AI)\n",
        "\n",
        "3 - semantic meaning search using Pinecone dense vectors (RAG AI)\n",
        "\n",
        "4 - Always check this rule"
      ],
      "metadata": {
        "id": "B5fVOFhy7Pah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(HTML('''\n",
        "<style>\n",
        "     label {\n",
        "         display: block;\n",
        "         margin-bottom: 5px;\n",
        "         font-weight: bold;\n",
        "         width: 100%;\n",
        "     }\n",
        "     select, textarea {\n",
        "         width: 100%;\n",
        "         padding: 10px;\n",
        "         margin-bottom: 15px;\n",
        "         border: 1px solid #ccc;\n",
        "         border-radius: 4px;\n",
        "         font-size: 14px;\n",
        "         height: 100%;\n",
        "     }\n",
        "     button {\n",
        "         background-color: #4CAF50;\n",
        "         color: white;\n",
        "         padding: 10px 20px;\n",
        "         border: none;\n",
        "         border-radius: 4px;\n",
        "         cursor: pointer;\n",
        "         font-size: 16px;\n",
        "     }\n",
        "     button:hover {\n",
        "         background-color: #45a049;\n",
        "     }\n",
        " </style>\n",
        "'''))\n",
        "\n",
        "model_dropdown = widgets.Dropdown(\n",
        "    options=['gpt-4o-mini'],\n",
        "    value='gpt-4o-mini',\n",
        "    description='Model:',\n",
        "    layout=widgets.Layout(width='30%', height='50px')\n",
        ")\n",
        "\n",
        "# Sample text from an article for initial test\n",
        "\n",
        "input_text = widgets.Textarea(value='He easily adapts to the latest technology.\\nPeople run the 1,500m and take part in a 5,000m race. \\nHe was an early adopter of the new technology.\\nThe newspaper goes to press at 10:30 PM.\\nThe car collided with a pedestrian.\\nHis excellency, the archbishop was there',\n",
        "    placeholder='Type the input text here',\n",
        "    description='Article:',\n",
        "    layout=widgets.Layout(width='80%', height='375px')\n",
        ")\n",
        "\n",
        "output = widgets.Output()\n",
        "\n",
        "generate_button = widgets.Button(description=\"Generate Output\")\n",
        "\n",
        "\n",
        "def on_generate_button_click(b):\n",
        "    with output:\n",
        "        output.clear_output()\n",
        "        try:\n",
        "          generate_output(input_text.value, model_dropdown.value)\n",
        "        except AttributeError as e:\n",
        "          print(\"AttributeError:\", e)\n",
        "        except Exception as e:\n",
        "          print(\"An error occurred:\", e)\n",
        "\n"
      ],
      "metadata": {
        "id": "S_PF6JKzkvex",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "403d83eb-2ba7-4c6d-acc6-52a7b3946a8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "     label {\n",
              "         display: block;\n",
              "         margin-bottom: 5px;\n",
              "         font-weight: bold;\n",
              "         width: 100%;\n",
              "     }\n",
              "     select, textarea {\n",
              "         width: 100%;\n",
              "         padding: 10px;\n",
              "         margin-bottom: 15px;\n",
              "         border: 1px solid #ccc;\n",
              "         border-radius: 4px;\n",
              "         font-size: 14px;\n",
              "         height: 100%;\n",
              "     }\n",
              "     button {\n",
              "         background-color: #4CAF50;\n",
              "         color: white;\n",
              "         padding: 10px 20px;\n",
              "         border: none;\n",
              "         border-radius: 4px;\n",
              "         cursor: pointer;\n",
              "         font-size: 16px;\n",
              "     }\n",
              "     button:hover {\n",
              "         background-color: #45a049;\n",
              "     }\n",
              " </style>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Pinecone index\n"
      ],
      "metadata": {
        "id": "Tfcnk6jZQMHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pinecone = Pinecone(api_key=PCApi)\n",
        "\n",
        "cloud = os.environ.get('PINECONE_CLOUD') or 'aws'\n",
        "region = os.environ.get('PINECONE_REGION') or 'us-east-1'\n",
        "spec = ServerlessSpec(cloud=cloud, region=region)\n",
        "\n",
        "index_name = 'semantic-search-fast3'\n",
        "pinecone.delete_index(index_name)\n",
        "\n",
        "pinecone.create_index(\n",
        "    name='semantic-search-fast3',\n",
        "    #dimension=1536,  # 1536 is the dimension used with text-embedding-ada-002 or 3072 for text-embedding-3-small (if used)\n",
        "    dimension=3072,  # 3072 is the dimension used with text-embedding-3-large\n",
        "    metric='dotproduct',\n",
        "    spec=spec\n",
        ")\n",
        "index = pinecone.Index('semantic-search-fast3')"
      ],
      "metadata": {
        "id": "Ly2Y82I2s4mf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "63dd08b6-346f-4ede-e58c-24e96d07e7f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "PineconeApiException",
          "evalue": "(409)\nReason: Conflict\nHTTP response headers: HTTPHeaderDict({'content-type': 'text/plain; charset=utf-8', 'access-control-allow-origin': '*', 'vary': 'origin,access-control-request-method,access-control-request-headers', 'access-control-expose-headers': '*', 'x-pinecone-api-version': '2024-04', 'X-Cloud-Trace-Context': '75fc37ea95dc0bb86ab08551920d2f89', 'Date': 'Wed, 15 Jan 2025 14:02:12 GMT', 'Server': 'Google Frontend', 'Content-Length': '85', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\nHTTP response body: {\"error\":{\"code\":\"ALREADY_EXISTS\",\"message\":\"Resource  already exists\"},\"status\":409}\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPineconeApiException\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-380192fcf0dc>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Index '{index_name}' already exists. Connecting to the index...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   pinecone.create_index(\n\u001b[0m\u001b[1;32m     14\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'semantic-search-fast3'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0;31m#dimension=1536,  # 1536 is the dimension used with text-embedding-ada-002 or 3072 for text-embedding-3-small (if used)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pinecone/control/pinecone.py\u001b[0m in \u001b[0;36mcreate_index\u001b[0;34m(self, name, dimension, spec, metric, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mapi_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate_index_request\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCreateIndexRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimension\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdimension\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mServerlessSpec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m             \u001b[0mapi_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate_index_request\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCreateIndexRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimension\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdimension\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPodSpec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mapi_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate_index_request\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCreateIndexRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimension\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdimension\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pinecone/core/client/api_client.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         \"\"\"\n\u001b[0;32m--> 771\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_http_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pinecone/core/client/api/manage_indexes_api.py\u001b[0m in \u001b[0;36m__create_index\u001b[0;34m(self, create_index_request, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'create_index_request'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0mcreate_index_request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_with_http_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         self.create_index = _Endpoint(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pinecone/core/client/api_client.py\u001b[0m in \u001b[0;36mcall_with_http_info\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'header'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Content-Type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mheader_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         return self.api_client.call_api(\n\u001b[0m\u001b[1;32m    834\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'endpoint_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'http_method'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pinecone/core/client/api_client.py\u001b[0m in \u001b[0;36mcall_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, async_req, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[1;32m    406\u001b[0m         \"\"\"\n\u001b[1;32m    407\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0masync_req\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m             return self.__call_api(resource_path, method,\n\u001b[0m\u001b[1;32m    409\u001b[0m                                    \u001b[0mpath_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m                                    \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpost_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pinecone/core/client/api_client.py\u001b[0m in \u001b[0;36m__call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mPineconeApiException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pinecone/core/client/api_client.py\u001b[0m in \u001b[0;36m__call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0;31m# perform request and return response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m             response_data = self.request(\n\u001b[0m\u001b[1;32m    196\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheader_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m                 \u001b[0mpost_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpost_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pinecone/core/client/api_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, query_params, headers, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    452\u001b[0m                                             body=body)\n\u001b[1;32m    453\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m             return self.rest_client.POST(url,\n\u001b[0m\u001b[1;32m    455\u001b[0m                                          \u001b[0mquery_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m                                          \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pinecone/core/client/rest.py\u001b[0m in \u001b[0;36mPOST\u001b[0;34m(self, url, headers, query_params, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    299\u001b[0m     def POST(self, url, headers=None, query_params=None, post_params=None,\n\u001b[1;32m    300\u001b[0m              body=None, _preload_content=True, _request_timeout=None):\n\u001b[0;32m--> 301\u001b[0;31m         return self.request(\"POST\", url,\n\u001b[0m\u001b[1;32m    302\u001b[0m                             \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m                             \u001b[0mquery_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pinecone/core/client/rest.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, query_params, headers, body, post_params, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    258\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mServiceException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_resp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mPineconeApiException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_resp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mPineconeApiException\u001b[0m: (409)\nReason: Conflict\nHTTP response headers: HTTPHeaderDict({'content-type': 'text/plain; charset=utf-8', 'access-control-allow-origin': '*', 'vary': 'origin,access-control-request-method,access-control-request-headers', 'access-control-expose-headers': '*', 'x-pinecone-api-version': '2024-04', 'X-Cloud-Trace-Context': '75fc37ea95dc0bb86ab08551920d2f89', 'Date': 'Wed, 15 Jan 2025 14:02:12 GMT', 'Server': 'Google Frontend', 'Content-Length': '85', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\nHTTP response body: {\"error\":{\"code\":\"ALREADY_EXISTS\",\"message\":\"Resource  already exists\"},\"status\":409}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare lists of rules and entries"
      ],
      "metadata": {
        "id": "0AKx9WECxMNO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "df['Style Point'] = df['Style Point'].str.replace('**', '', regex=False)\n",
        "\n",
        "# Replace null values in keywords with 'Our Style' column\n",
        "df['Our Style'].fillna(df['Keywords'], inplace=True)\n",
        "df['Our Style'].replace('', 'placeholder text', inplace=True)\n",
        "df['Our Style'].fillna('placeholder text', inplace=True)\n",
        "\n",
        "df_filtered = df[df[\"Type\"] == 3]\n",
        "\n",
        "\n",
        "ID_list = df_filtered[\"ID\"].tolist()\n",
        "type_list = df_filtered[\"Type\"].tolist()\n",
        "keywords_list = df_filtered[\"Keywords\"].tolist()\n",
        "\n",
        "rule_list = df_filtered.apply(\n",
        "    lambda row: (\n",
        "        row[\"Style Point\"] + ' ' +\n",
        "        row[\"Our Style\"] +\n",
        "        (' Examples of correct usage: ' + row[\"Correct usage\"] if pd.notna(row[\"Correct usage\"]) and row[\"Correct usage\"] != '' else '') +\n",
        "        (' Examples of incorrect usage: ' + row[\"Incorrect usage\"] if pd.notna(row[\"Incorrect usage\"]) and row[\"Incorrect usage\"] != '' else '')\n",
        "    ),\n",
        "    axis=1\n",
        ").tolist()\n",
        "\n",
        "#print(f\"rule_list: {rule_list}\")\n",
        "# TO REMOVE - Keep track of rule ids to check what is going into embeddings.\n",
        "rule_ids = df_filtered[\"ID\"].tolist()\n",
        "\n",
        "# Remove final , in csv of keywords if exists\n",
        "def clean_comma_delimited_list(myListString):\n",
        "  if myListString.endswith(','):\n",
        "      myListString = myListString[:-1]\n",
        "  return myListString\n",
        "\n",
        "def limit_rule_ids(matched_rule_ids):\n",
        "\n",
        "    # make a hard limit of rules in case too many are found\n",
        "    limit_rules_genai = 20\n",
        "\n",
        "    if len(matched_rule_ids) >= limit_rules_genai:\n",
        "\n",
        "        matched_rule_ids = matched_rule_ids[:limit_rules_genai]\n",
        "\n",
        "    rule_ids_comma_delimited_string = \",\".join(map(str, matched_rule_ids))\n",
        "    return rule_ids_comma_delimited_string\n"
      ],
      "metadata": {
        "id": "KR-b1vAes-R8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e024464-66a4-4c79-a97f-f3ccededa945"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-bc3816b616f2>:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Our Style'].fillna(df['Keywords'], inplace=True)\n",
            "<ipython-input-10-bc3816b616f2>:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Our Style'].replace('', 'placeholder text', inplace=True)\n",
            "<ipython-input-10-bc3816b616f2>:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Our Style'].fillna('placeholder text', inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Narrow down rules from guideline to a subset to run in a prompt.\n",
        "\n",
        "*   More performant\n",
        "*   Less cost (fewer tokens)\n",
        "\n",
        "## Pinecone settings\n",
        "\n",
        "###### Setting the score needs experimentation.\n",
        "\n",
        "###### If too many false positive found, consider:\n",
        "\n",
        "*   increasing the score\n",
        "*  improving the comprehensibility of the guidelines found by pinecone search (in our case, type 3 rules)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kZsaeVKvxUuW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def narrow_down_rules(textToValidate):\n",
        "\n",
        "  top_k = 10  # Limit number of results to return by pinecone query to ensure efficiency.\n",
        "\n",
        "  matched_rule_ids_all = []\n",
        "  matched_rule_ids_string_search_with_ai = []\n",
        "  matched_rule_ids_dense = []\n",
        "  matched_rule_ids_always = []\n",
        "\n",
        "  for i in range(len(df)):\n",
        "      myType = df.loc[i, 'Type']\n",
        "      rule_id = df.loc[i, 'ID']\n",
        "      keyword_csv = df.loc[i, 'Keywords']\n",
        "      keyword_csv = clean_comma_delimited_list(keyword_csv)\n",
        "\n",
        "      # FIND TYPE 2 RULES - Do string search for rules with a list of keywords to match in the article\n",
        "\n",
        "      if myType == 2:\n",
        "          relevant_sentences = []\n",
        "          matched = False  # Reset matched for each rule\n",
        "\n",
        "          for keyword in keyword_csv.split(','):\n",
        "              keyword = keyword.strip().lower()\n",
        "\n",
        "              # find matches to keywords of complete words only\n",
        "              matched_sentences = [\n",
        "                sentence.strip() for sentence in textToValidate.split('.')\n",
        "                if (f\" {keyword} \" in f\" {sentence.lower()} \" or  # keyword in the middle\n",
        "                  sentence.lower().startswith(f\"{keyword} \") or  # keyword at the start\n",
        "                  sentence.lower().endswith(f\" {keyword}\"))      # keyword at the end\n",
        "              ]\n",
        "\n",
        "              if matched_sentences:\n",
        "                  matched = True\n",
        "                  myID = int(df.loc[i, 'ID'])\n",
        "                  myKeywords = df.loc[i, 'Keywords']\n",
        "                  relevant_sentences.extend(matched_sentences)\n",
        "                  break  # Stop checking further if a match is found within this rule\n",
        "          if matched:\n",
        "            sentenceCount = 0\n",
        "            for sentence in relevant_sentences:\n",
        "                sentenceCount += 1\n",
        "                print(f\"Found {myKeywords} in {sentenceCount} sentences, Rule ID: {myID}\")\n",
        "                print(f\"Sentence: '{sentence}'\")\n",
        "                if myID not in matched_rule_ids_string_search_with_ai:\n",
        "                  matched_rule_ids_string_search_with_ai.append(str(int(myID)))\n",
        "\n",
        "          # Convert ID array to strings - to match format of dense array\n",
        "          matched_rule_ids_string_search_with_ai = [str(item) for item in matched_rule_ids_string_search_with_ai]\n",
        "\n",
        "      # FIND TYPE 4 RULES\n",
        "\n",
        "      elif myType == 4:\n",
        "        myID = int(df.loc[i, 'ID'])\n",
        "        matched_rule_ids_always.append(str(int(myID)))\n",
        "\n",
        "  # FIND TYPE 3 RULES\n",
        "\n",
        "  # Generate embeddings a second time, for the article text\n",
        "  # (in order to query against the stored rule embeddings)\n",
        "\n",
        "  query_dense = get_embeddings([textToValidate])[0]\n",
        "\n",
        "  # ========================================================\n",
        "\n",
        "  # Calculate cost of embeddings creation for rule_list ...\n",
        "  encoder = tiktoken.encoding_for_model(\"text-embedding-3-large\")\n",
        "  embedding_tokens_article = len(encoder.encode(textToValidate))\n",
        "\n",
        "  # - for Open AI embeddings model\n",
        "\n",
        "  embedding_article_cost = calculate_token_usage_cost(embedding_tokens_article, text_embedding_3_large_tokens_cost_per_million)\n",
        "\n",
        "  print(f\"Embedding tokens used for article: {embedding_tokens_article}\")\n",
        "  print(f\"Cost for embeddings for article: ${embedding_article_cost:.6f}\")\n",
        "\n",
        "  # = for Pinecone\n",
        "\n",
        "  query_vectors = 1  # Number of query vectors (textToValidate)\n",
        "  read_units = query_vectors * (top_k / 10)  # 1 read unit per 10 results\n",
        "\n",
        "  pinecone_cost_query = calculate_pinecone_cost(read_units, 0, 0, 0, 0)  # Only read units\n",
        "  print(f\"Pinecone cost currently free on starter plan but estimate based on lowest rate for standard plan:\\n  Pinecone Cost for querying: ${pinecone_cost_query:.6f}\")\n",
        "\n",
        "  #1 Query the index with dense embedding\n",
        "  query_response = index.query(\n",
        "        top_k=top_k,\n",
        "        vector=query_dense,  # Running query on dense vector\n",
        "        include_metadata=True\n",
        "  )\n",
        "\n",
        "  for match in query_response['matches']:\n",
        "          myType = match[\"metadata\"][\"type\"]\n",
        "          myID = str(int(match[\"metadata\"][\"ID\"]))\n",
        "          score = match[\"score\"]\n",
        "          print(\"myID\", myID, \" score:\", score)\n",
        "\n",
        "\n",
        "          if score > 0.28:  # Experiment with increasing/decreasing score to find more/less rules\n",
        "            matched_rule_ids_dense.append(str(int(myID)))\n",
        "\n",
        "\n",
        "  matched_rules_filtered = [item for item in matched_rule_ids_string_search_with_ai if item not in matched_rule_ids_dense]\n",
        "\n",
        "  matched_rule_ids_all = matched_rule_ids_string_search_with_ai + matched_rule_ids_dense + matched_rule_ids_always\n",
        "\n",
        "  print(\"Matched Rule IDs Type 2 - String search on keywords:\", matched_rule_ids_string_search_with_ai)\n",
        "\n",
        "  print(f\"Matched Rule IDs Type 3 - Meaning search on keywords - Pinecone: \", matched_rule_ids_dense)\n",
        "\n",
        "  print(\"Matched Rule IDs Type 4 - Always checked via prompt:\", matched_rule_ids_always)\n",
        "\n",
        "  print(\"All Matched Rule IDs:\", matched_rule_ids_all)\n",
        "\n",
        "  # Generate a formatted string of rules for matched_rule_ids_all\n",
        "  string_of_rules = \"\"\n",
        "  for rule_id in matched_rule_ids_all:\n",
        "        row = df.loc[df['ID'] == int(rule_id)]\n",
        "        if not row.empty:\n",
        "            rule_text = (\n",
        "                f\"Rule {row['ID'].values[0]}\\n\"\n",
        "                f\"{row['Style Point'].values[0]}\\n\"\n",
        "                f\"{row['Our Style'].values[0]}\\n\"\n",
        "            )\n",
        "            # Add correct and incorrect usage examples if available\n",
        "            if pd.notna(row['Correct usage'].values[0]):\n",
        "                rule_text += f\"This is correct usage:\\n{row['Correct usage'].values[0]}\\n\"\n",
        "            if pd.notna(row['Incorrect usage'].values[0]):\n",
        "                rule_text += f\"This is incorrect usage:\\n{row['Incorrect usage'].values[0]}\\n\"\n",
        "\n",
        "            # Append this rule text to the overall string with line breaks\n",
        "            string_of_rules += f\"{rule_text}\\n\\n\"\n",
        "\n",
        "  print(f\"=============\")\n",
        "  return matched_rule_ids_all, embedding_tokens_article, embedding_article_cost, string_of_rules;\n",
        "\n"
      ],
      "metadata": {
        "id": "Svzgab58nWAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate embeddings using OpenAI's embeddings models\n",
        "\n",
        "Our tests found text-embedding-3-large gave better results than text-embedding-ada-002 or text-embedding-3-small, from the Open AI suite of embedding models currently available"
      ],
      "metadata": {
        "id": "A9SSc3Urt92g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embeddings(rule_list):\n",
        "    response = openai.Embedding.create(\n",
        "        input=rule_list,\n",
        "        model=\"text-embedding-3-large\"\n",
        "    )\n",
        "    embeddings = [embedding['embedding'] for embedding in response['data']]\n",
        "\n",
        "    return embeddings\n",
        "\n",
        "# Generate embeddings the first time, from the rules, to store in pinecone\n",
        "embeddings = get_embeddings(rule_list)\n",
        "\n",
        "# Calculate costs for embeddings creation for rule_list\n",
        "\n",
        "# - for Open AI model\n",
        "encoder = tiktoken.encoding_for_model(\"text-embedding-3-large\")\n",
        "embedding_tokens_rule_list = sum([len(encoder.encode(text)) for text in rule_list])\n",
        "text_embedding_3_large_tokens_cost_per_million = 0.13\n",
        "embedding_rule_list_token_cost = calculate_token_usage_cost(embedding_tokens_rule_list, text_embedding_3_large_tokens_cost_per_million)\n",
        "\n",
        "# Print token and cost information\n",
        "print(f\"Embedding tokens used for rule_list: {embedding_tokens_rule_list}\")\n",
        "print(f\"Cost for embeddings for rule_list: ${embedding_rule_list_token_cost:.6f}\")\n",
        "\n",
        "# - for Pinecone\n",
        "vector_size_in_bytes = 3072 * 4  # 3072 dimensions, float32 (4 bytes)\n",
        "num_upsert_vectors = len(embeddings)  # Number of vectors stored\n",
        "\n",
        "write_units = num_upsert_vectors / 1000  # 1 write unit per 1000 vectors\n",
        "\n",
        "# Calculate Pinecone cost for storing and upserting vectors\n",
        "pinecone_cost_rules = calculate_pinecone_cost(0, write_units, storage_cost_per_gb, vector_size_in_bytes, num_upsert_vectors)\n",
        "print(f\"Pinecone Cost currently free on starter plan but estimate based on lowest rate for standard plan - for storing and upserting rules: ${pinecone_cost_rules:.6f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YPDsEkrMhArW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "454e3727-a29c-4c1c-e682-6ac25733f523"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding tokens used for rule_list: 422\n",
            "Cost for embeddings for rule_list: $0.000055\n",
            "Pinecone Cost currently free on starter plan but estimate based on lowest rate for standard plan - for storing and upserting rules: $0.000008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare records for upsert in Pinecone"
      ],
      "metadata": {
        "id": "1le_U_MGvVBu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "records = []\n",
        "for i in range(len(embeddings)):\n",
        "    ind_dic = {\n",
        "        'id': f'vec{i+1}',\n",
        "        'values': embeddings[i],\n",
        "        'metadata': {\n",
        "            'rule': rule_list[i],\n",
        "            'ID': ID_list[i],\n",
        "            'type': type_list[i],\n",
        "        }\n",
        "    }\n",
        "    records.append(ind_dic)\n",
        "\n",
        "\n",
        "index.upsert(vectors=records)"
      ],
      "metadata": {
        "id": "MpNzT2PevQtk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da61ae0d-cb5d-4516-f3e9-f8fac46b2780"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'upserted_count': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use function call to set the json output format of prompt"
      ],
      "metadata": {
        "id": "PI7FRXxgnobq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result_functions = [\n",
        "    {\n",
        "        'name': 'validate_article_compliance',\n",
        "        'description': 'Validate article compliance with rules',\n",
        "        'parameters': {\n",
        "            'type': 'object',\n",
        "            'properties': {\n",
        "                'isArticleCompliantWithAllRules': {\n",
        "                    'type': 'boolean',\n",
        "                    'description': 'Indicates whether the article complies with all rules.'\n",
        "                },\n",
        "                'issuesOfNonCompliance': {\n",
        "                    'type': 'array',\n",
        "                    'items': {\n",
        "                        'type': 'object',\n",
        "                        'properties': {\n",
        "                            'ruleID': {\n",
        "                                'type': 'string',\n",
        "                                'description': 'Rule ID'\n",
        "                            },\n",
        "                            'stylePoint': {\n",
        "                                'type': 'string',\n",
        "                                'description': 'Style Point'\n",
        "                            },\n",
        "                            'ourStyle': {\n",
        "                                'type': 'string',\n",
        "                                'description': 'Our Style'\n",
        "                            },\n",
        "                            'textWithProblem': {\n",
        "                                'type': 'string',\n",
        "                                'description': 'Text containing the compliance issue.'\n",
        "                            },\n",
        "                            'suggestedAlternative': {\n",
        "                                'type': 'string',\n",
        "                                'description': 'Suggested alternative text.'\n",
        "                            },\n",
        "                            'explanation': {\n",
        "                                'type': 'string',\n",
        "                                'description': 'Explanation of the issue.'\n",
        "                            }\n",
        "                        }\n",
        "                    },\n",
        "                    'description': 'List of compliance issues.'\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "]\n"
      ],
      "metadata": {
        "id": "o2EP1weNpJ44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run prompt using Open AI\n",
        "## the latest models got the best results from our tests"
      ],
      "metadata": {
        "id": "Vb76Wrt4v3_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_compliance_check(guideline, text, matched_rule_ids, model, embedding_tokens_article, embedding_article_cost, string_of_rules):\n",
        "\n",
        "    rule_ids_formatted_for_prompt = limit_rule_ids(matched_rule_ids)\n",
        "\n",
        "    print('matched_rule_ids', matched_rule_ids)\n",
        "\n",
        "\n",
        "    # Generate prompt preamble before listing all rules\n",
        "    prompt = f\"\"\"Here are the rules. \\n\\n\n",
        "        Go through rule IDs {string_of_rules} only) provided in the uploaded style guide (ignore all other rules), and in each case, state if the provided input text is compliant with each of the rules.\n",
        "        In each case, state if the provided input text is compliant with each of the following rules.\n",
        "        If the context is not found, do not apply the guideline, and state that the text is compliant.\n",
        "        If the context is not certain, ignore the guideline and state that the rule is compliant.\n",
        "        Provide an explanation in each case.\n",
        "        Return a json array as a result.\n",
        "        The json must have the format as stated in the function call\n",
        "        There should be one result per rule ID that is not compliant in one array.\n",
        "        Only the provided rules should be used and that any external information or assumptions should be excluded.\n",
        "        Then there should be one overall value of isArticleCompliantWithAllRules (true/false). When a ruleID is output in Json format it as an Integer\"\"\"\n",
        "\n",
        "    # Alternative prompt - also works\n",
        "    #prompt = f\"\"\"You are the editor-in-chief at an international news agency, tasked with revising and verifying all copy before publication.\n",
        "    #  Your responsibilities include:\n",
        "    #  Reading Text Inputs: Analyze each text input against established guidelines.\n",
        "    #  Go through rules  {string_of_rules}\n",
        "    #  Output Requirements:\n",
        "    #  Provide explanations for each non-compliant rule.\n",
        "    #  Return a JSON array with:\n",
        "    #  Each non-compliant rule ID.\n",
        "    #  A single overall value of isArticleCompliantWithAllRules (true/false).\"\"\"\n",
        "\n",
        "    # print(\"Generated Prompt:\\n\", prompt)\n",
        "\n",
        "    send_prompt = (\n",
        "        f\"{prompt}\\n\\n\"\n",
        "        f\"Guideline: {guideline}\\n\\n\"\n",
        "        f\"Text: {text}\\n\\n\"\n",
        "    )\n",
        "\n",
        "\n",
        "    start_time = time.time()\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=[{\"role\": \"user\", \"content\": send_prompt}],\n",
        "        temperature=0,\n",
        "        functions = result_functions,\n",
        "        function_call = 'auto'\n",
        "    )\n",
        "\n",
        "    # Get costs of tokens depending on model used\n",
        "    genai_input_tokens_cost_per_million, genai_output_tokens_cost_per_million = get_token_costs(model)\n",
        "\n",
        "    # Get the input tokens\n",
        "    usage = response['usage']\n",
        "    genAI_input_tokens = usage['prompt_tokens']\n",
        "    genAI_input_token_cost = calculate_token_usage_cost(genAI_input_tokens, genai_input_tokens_cost_per_million)\n",
        "    print(f\"GenAI Input tokens: {genAI_input_tokens} - cost this time: ${genAI_input_token_cost:.6f}\")\n",
        "\n",
        "    # Get the output tokens\n",
        "    genAI_output_tokens = usage['completion_tokens']\n",
        "    genAI_output_token_cost = calculate_token_usage_cost(genAI_output_tokens, genai_output_tokens_cost_per_million)\n",
        "    print(f\"GenAI Output tokens: {genAI_output_tokens} - cost this time: ${genAI_output_token_cost:.6f}\")\n",
        "\n",
        "    genAI_token_cost = genAI_input_token_cost + genAI_output_token_cost\n",
        "    print(f\"Total genAI cost this time: ${genAI_token_cost:.6f}\")\n",
        "\n",
        "    end_time = time.time()\n",
        "    encoder = tiktoken.encoding_for_model(model)\n",
        "    tokens = encoder.encode(send_prompt)\n",
        "\n",
        "    # cost true as of 2024\n",
        "    text_embedding_3_large_tokens_cost_per_million = 0.13\n",
        "\n",
        "    tokens_embedding = sum([len(encoder.encode(send_prompt)) for text in rule_list])\n",
        "    embedding_token_cost = calculate_token_usage_cost(tokens_embedding, text_embedding_3_large_tokens_cost_per_million)\n",
        "    print(f\"Embedding tokens used for rules: {tokens_embedding} - Cost this time: ${embedding_token_cost:.6f}\")\n",
        "\n",
        "    total_openAI_cost = embedding_token_cost + genAI_token_cost\n",
        "    print(f\"Total OpenAI cost: ${total_openAI_cost:.6f}\")\n",
        "    print(f\"Gen AI call time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "\n",
        "    json_response = '';\n",
        "\n",
        "    try:\n",
        "        json_response = json.loads(response.choices[0].message.get(\"function_call\", {}).get(\"arguments\", \"{}\"))\n",
        "        formatted_json = json.dumps(json_response, indent=2)\n",
        "    except json.JSONDecodeError:\n",
        "        formatted_json = \"Invalid JSON response or no function call arguments.\"\n",
        "\n",
        "    print('formatted_json', formatted_json)\n",
        "\n",
        "\n",
        "    return json_response, embedding_tokens_article, embedding_article_cost"
      ],
      "metadata": {
        "id": "rmPWbQ24wPKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compile rule to run in prompt from sheet columns\n",
        "### Format of rule generated from sheet columns\n",
        "### {Rule ID} {Style Point} {Our Style}\n",
        "### correct Usage: {List of correct usage examples}\n",
        "### incorrect Usage: {List of incorrect usage examples}\n"
      ],
      "metadata": {
        "id": "WfILL3McwWjW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_guideline_from_df(df):\n",
        "    guidelines = []\n",
        "    for i, row in df.iterrows():\n",
        "        parts = []  # List to hold the parts of the guideline\n",
        "\n",
        "        if pd.notna(row['ID']):\n",
        "            parts.append(f\"Rule {row['ID']}\")\n",
        "        if pd.notna(row['Style Point']):\n",
        "            parts.append(f\"{row['Style Point']}\")\n",
        "        if pd.notna(row['Our Style']):\n",
        "            parts.append(f\"{row['Our Style']}\")\n",
        "        if pd.notna(row['Correct usage']):\n",
        "            parts.append(f\"This type of usage is correct: {row['Correct usage']}\")\n",
        "        if pd.notna(row['Incorrect usage']):\n",
        "            parts.append(f\"This type of usage is incorrect: {row['Incorrect usage']}\")\n",
        "\n",
        "        # Join the parts with a newline, only if there are any parts to join\n",
        "        if parts:\n",
        "            guideline = \"\\n\".join(parts)\n",
        "            guidelines.append(guideline)\n",
        "\n",
        "    return \"\\n\\n\".join(guidelines)  # Separate each guideline by an extra newline\n"
      ],
      "metadata": {
        "id": "g9fapFVPwutl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate output when form button is clicked.\n",
        "## Output shows below the form in the grey area"
      ],
      "metadata": {
        "id": "KiM6nfd1w0YF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_output(example, model):\n",
        "\n",
        "    matched_rule_ids, embedding_tokens_article, embedding_article_cost, string_of_rules = narrow_down_rules(example)\n",
        "    guideline = generate_guideline_from_df(df)\n",
        "    response = get_compliance_check(guideline, example, matched_rule_ids, model, embedding_tokens_article, embedding_article_cost, string_of_rules)\n",
        "\n",
        "generate_button.on_click(on_generate_button_click)\n",
        "\n",
        "display(widgets.VBox([model_dropdown, input_text, generate_button, output]))\n",
        "\n",
        "class Document:\n",
        "    def __init__(self, page_content, metadata):\n",
        "        self.page_content = page_content\n",
        "        self.metadata = metadata"
      ],
      "metadata": {
        "id": "FVZnxqizuSIP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b1a9198b3edb420ebba8e78d71cbf26e",
            "1d92eaadb2514b35a65101a866007b22",
            "848762add25c436eb830c723d1e3a5ae",
            "8fc356c90b584081b2fafdc006b9431b",
            "5288e5c9196b4727a91e4d92e43e2bcf",
            "33cd34dc4f0d478ab4161c655ce7085a",
            "7b06834509884b86a22711bbc8d50828",
            "df4cfcba974749489ab0dd9faa06d88e",
            "49554bbb034342f6a5ad37ec8f24e751",
            "edeabbf9aec34402b3b15824dfabd839",
            "d2244c1c8b1245dcabf31e2300eba8a6",
            "72fba0797aab4c1aa6f9c1c529af9640",
            "c5f3910b458743328d9bad1688242406"
          ]
        },
        "outputId": "72610638-4865-4f3e-b4cc-1092646d38a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Dropdown(description='Model:', layout=Layout(height='50px', width='30%'), options=('gpt-4o-mini…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b1a9198b3edb420ebba8e78d71cbf26e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# First basic Tests\n",
        "\n",
        "*   Amend text above \"The car collided with a pedestrian.\" to \"The car hit a pedestrian\" and click on \"Generate Output\".\n",
        "Check the results below - it should identify an additional non-compliant rule\n",
        "*   Copy this colab - then upload your own Style_Guide.xlsx with some test rules to see well they work\n",
        "\n"
      ],
      "metadata": {
        "id": "lIByejJ_Mzi4"
      }
    }
  ]
}