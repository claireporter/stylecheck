{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0bdd839d942249ee8e392c419707a6d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e49786e060464be2af51f65a262236c2",
              "IPY_MODEL_158539c832e341c680336fd9f8858c8b",
              "IPY_MODEL_90140fa876f94d1e875049f15e0502ec",
              "IPY_MODEL_9c44bf616e3842dba678783cf260210c"
            ],
            "layout": "IPY_MODEL_dfa4ae36950a41d8a3d05b0c8d2b540a"
          }
        },
        "e49786e060464be2af51f65a262236c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "gpt-4o-mini"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Model:",
            "description_tooltip": null,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_5f9500dcbe7f4805824f0539616d8f7a",
            "style": "IPY_MODEL_ffdba4d4d822450fb6a7ddcb6bba5bb4"
          }
        },
        "158539c832e341c680336fd9f8858c8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "Article:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_53e3261c1f154288802961323f90b2c5",
            "placeholder": "Type the input text here",
            "rows": null,
            "style": "IPY_MODEL_c81e395aaea444ce970f24e6cd998149",
            "value": "He easily adapts to the latest technology.\nPeople run the 1,500m and take part in a 5,000m race. \nHe was an early adopter of the new technology.\nThe newspaper goes to press at 10:30 PM.\nThe car collided with a pedestrian.\nHis excellency, the archbishop was there"
          }
        },
        "90140fa876f94d1e875049f15e0502ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Generate Output",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_8c4914d640fd42fb904ef5884e8eea27",
            "style": "IPY_MODEL_b5575f0c87e24986bc885a823eba8e0d",
            "tooltip": ""
          }
        },
        "9c44bf616e3842dba678783cf260210c": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_0d31c13bd1884d41b24831a66b396503",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Found adapter, adaptor, adopt, adapt, adopts, adapts in 1 sentences, Rule ID: 11\n",
                  "Sentence: 'He easily adapts to the latest technology'\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Embedding tokens used for article: 69\n",
                  "Cost for embeddings for article: $0.000009\n",
                  "Pinecone cost currently free on starter plan but estimate based on lowest rate for standard plan:\n",
                  "  Pinecone Cost for querying: $0.000016\n",
                  "Matched Rule IDs Type 2 - String search on keywords: ['11']\n",
                  "Matched Rule IDs Type 3 - Meaning search on keywords - Pinecone:  []\n",
                  "Matched Rule IDs Type 4 - Always checked via prompt: ['8']\n",
                  "All Matched Rule IDs: ['11', '8']\n",
                  "=============\n",
                  "matched_rule_ids ['11', '8']\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "GenAI Input tokens: 1550 - cost this time: $0.000232\n",
                  "GenAI Output tokens: 166 - cost this time: $0.000100\n",
                  "Total genAI cost this time: $0.000332\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Embedding tokens used for rules: 2836 - Cost this time: $0.000369\n",
                  "Total OpenAI cost: $0.000701\n",
                  "Gen AI call time: 2.94 seconds\n",
                  "formatted_json {\n",
                  "  \"isArticleCompliantWithAllRules\": false,\n",
                  "  \"issuesOfNonCompliance\": [\n",
                  "    {\n",
                  "      \"ruleID\": \"11\",\n",
                  "      \"stylePoint\": \"adapter\",\n",
                  "      \"ourStyle\": \"adapter\",\n",
                  "      \"textWithProblem\": \"He was an early adopter of the new technology.\",\n",
                  "      \"suggestedAlternative\": \"He was an early adapter of the new technology.\",\n",
                  "      \"explanation\": \"The term 'adopter' is incorrectly used here; it should be 'adapter' as per the rule.\"\n",
                  "    },\n",
                  "    {\n",
                  "      \"ruleID\": \"9\",\n",
                  "      \"stylePoint\": \"Accidents and collisions\",\n",
                  "      \"ourStyle\": \"accident\",\n",
                  "      \"textWithProblem\": \"The car collided with a pedestrian.\",\n",
                  "      \"suggestedAlternative\": \"The car hit a pedestrian.\",\n",
                  "      \"explanation\": \"The term 'collided' is incorrect in this context; it should be 'hit' as per the rule.\"\n",
                  "    }\n",
                  "  ]\n",
                  "}\n"
                ]
              }
            ]
          }
        },
        "dfa4ae36950a41d8a3d05b0c8d2b540a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f9500dcbe7f4805824f0539616d8f7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "50px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "30%"
          }
        },
        "ffdba4d4d822450fb6a7ddcb6bba5bb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53e3261c1f154288802961323f90b2c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "375px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "80%"
          }
        },
        "c81e395aaea444ce970f24e6cd998149": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c4914d640fd42fb904ef5884e8eea27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5575f0c87e24986bc885a823eba8e0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "0d31c13bd1884d41b24831a66b396503": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/claireporter/stylecheck/blob/main/stylecheckAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **INPUT REQUIRED**\n",
        "Set up new key under Secrets in colab\n",
        "\n",
        "\n",
        "*   Name OPENAI_API_KEY\n",
        "*   Value Key name\n",
        "(Get from https://platform.openai.com/settings/organization/api-keys)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "d5coieAiVzLv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Irish Examiner Style Guide Check using Open AI and Pinecone\n",
        "\n",
        "## Import libraries"
      ],
      "metadata": {
        "id": "SyjBPkcjeobr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28\n",
        "# tiktoken only needed for cost evaluation, not actual runnind of the model on the article\n",
        "!pip install tiktoken\n",
        "!pip install -qU \\\n",
        "    pinecone-client==3.0.2 \\\n",
        "    openai==0.28.0\n",
        "\n",
        "import openai\n",
        "import json\n",
        "import os\n",
        "\n",
        "# time only needed for speed evaluation\n",
        "import time\n",
        "# tiktoken only needed for cost evaluation, not actual running of the model on the article\n",
        "import tiktoken\n",
        "# reading google sheet file\n",
        "import pandas as pd\n",
        "\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "from google.colab import drive, userdata\n",
        "\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "openai.api_key = api_key\n",
        "\n",
        "## Used for form in google colab\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# Add in the data file\n",
        "if not os.path.exists('data'):\n",
        "    os.makedirs('data')\n",
        "\n",
        "# Download the Style Guide directly from the GitHub raw URL\n",
        "file_url = \"https://raw.githubusercontent.com/claireporter/stylecheck/main/Style_Guide.xlsx\"\n",
        "destination_path = \"data/Style_Guide.xlsx\"\n",
        "!wget -O {destination_path} {file_url}\n",
        "\n"
      ],
      "metadata": {
        "id": "qXNyxmRT6yB4",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64ed7cae-aa06-4a5f-8c1b-b25809c0181e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.11.10)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.12.14)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->openai==0.28) (4.12.2)\n",
            "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.57.4\n",
            "    Uninstalling openai-1.57.4:\n",
            "      Successfully uninstalled openai-1.57.4\n",
            "Successfully installed openai-0.28.0\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.12.14)\n",
            "Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.8.0\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wTYZccq4enaV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Access the Style_Guide\n",
        "\n",
        "(sample of 10 rules)\n",
        "\n"
      ],
      "metadata": {
        "id": "jKA-5wyp46xx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add in the data file\n",
        "if not os.path.exists('data'):\n",
        "    os.makedirs('data')\n",
        "\n",
        "# Step 2: Download the file directly from the GitHub raw URL\n",
        "file_url = \"https://raw.githubusercontent.com/claireporter/stylecheck/main/Style_Guide.xlsx\"\n",
        "destination_path = \"data/Style_Guide.xlsx\"\n",
        "\n",
        "# Use wget to download the file\n",
        "!wget -O {destination_path} {file_url}\n",
        "\n",
        "print(f\"File has been downloaded to: {destination_path}\")"
      ],
      "metadata": {
        "id": "EGLZ4ypr02QZ",
        "outputId": "d61fec04-cc6a-4067-dcb9-988bd2893a3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-15 12:14:01--  https://raw.githubusercontent.com/claireporter/stylecheck/main/Style_Guide.xlsx\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12368 (12K) [application/octet-stream]\n",
            "Saving to: ‘data/Style_Guide.xlsx’\n",
            "\n",
            "data/Style_Guide.xl 100%[===================>]  12.08K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2025-01-15 12:14:02 (19.8 MB/s) - ‘data/Style_Guide.xlsx’ saved [12368/12368]\n",
            "\n",
            "File has been downloaded to: data/Style_Guide.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xlsx_file_path = \"/content/data/Style_Guide.xlsx\" # Update xlsx_file_path with downloaded file\n",
        "df = pd.read_excel(xlsx_file_path, sheet_name=\"Data Sheet\")\n"
      ],
      "metadata": {
        "id": "optvOhBq4k1D"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **INPUT OPTIONAL**\n",
        "## Adjust costs - costs below are for 2024 and depending on product plans, region"
      ],
      "metadata": {
        "id": "q8CZ1OYnOP_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Open AI Costs - Adjust according to open ai model pricing\n",
        "\n",
        "# Embedding model cost - text_embedding_3_large\n",
        "text_embedding_3_large_tokens_cost_per_million = 0.13\n",
        "#  Gen AI cost -  gpt-4o-mini\n",
        "gpt4o_mini_input_tokens_cost_per_million =  0.150 # ($s)\n",
        "gpt4o_mini_output_tokens_cost_per_million = 0.6 # ($s)\n",
        "\n",
        "# Pinecone costs - currently using free plan, but these are miniumum prices for the Standard plan\n",
        "\n",
        "# Price per GB - Adjust based on your pricing region\n",
        "storage_cost_per_gb = 0.33\n",
        "# Pinecone pricing for read units - adjust according to pinecone plan\n",
        "read_cost_per_million = 16\n",
        "# Pinecone pricing for write units - adjust according to pinecone plan\n",
        "write_cost_per_million = 4\n"
      ],
      "metadata": {
        "id": "niIWW_kODuhI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculate costs"
      ],
      "metadata": {
        "id": "Gs5AqMSi6v-r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "sUikxl3sECHY"
      },
      "outputs": [],
      "source": [
        "# Calculate Pinecone cost\n",
        "def calculate_pinecone_cost(read_units, write_units, storage_cost_per_gb, vector_size_in_bytes, num_vectors):\n",
        "    # Calculate storage cost\n",
        "    storage_cost = (num_vectors * vector_size_in_bytes) / 1e9 * storage_cost_per_gb\n",
        "\n",
        "    # Costs for read and write units\n",
        "    read_cost_per_unit = read_cost_per_million/1_000_000\n",
        "    write_cost_per_unit = write_cost_per_million/1_000_000\n",
        "    total_cost = (read_units * read_cost_per_unit) + (write_units * write_cost_per_unit) + storage_cost\n",
        "\n",
        "    return total_cost\n",
        "\n",
        "def calculate_token_usage_cost(tokens, cost_per_million):\n",
        "     cost_per_one_token = cost_per_million / 1000000\n",
        "     return (tokens * cost_per_one_token)\n",
        "\n",
        "def get_token_costs(model):\n",
        "\n",
        "    input_tokens_cost_per_million = gpt4o_mini_input_tokens_cost_per_million\n",
        "    output_tokens_cost_per_million = gpt4o_mini_output_tokens_cost_per_million\n",
        "    return input_tokens_cost_per_million, output_tokens_cost_per_million"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-PYtMMjY1g_1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **INPUT REQUIRED**\n",
        "#### Allow access to Google Drive\n",
        "#### **INPUT REQUIRED**\n",
        "#### Set up Pinecone\n",
        "#### Save PCapi.txt file to drive to connect to Pinecone"
      ],
      "metadata": {
        "id": "gN3E3PQMIrKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load guidelines as google sheet and do pinecone prep ie create pinecone embeddings\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "with open('/content/drive/MyDrive/PCapi.txt', 'r') as file:\n",
        "    PCApi = file.read().strip()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJFNPJ4nIohn",
        "outputId": "7977cb72-bdc3-467b-9bf9-da808e571d92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets view the structure of the guidelines\n",
        "\n",
        "# Select specific columns and rename them\n",
        "df_subset = df[['ID', 'Style Point', 'Our Style', 'Correct usage', 'Incorrect usage', 'Keywords', 'Type', 'Replace']].head(7)\n",
        "df_subset = df_subset.rename(columns={\n",
        "    'Style Point': 'Style Point (Style Name)',\n",
        "    'Our Style': 'Our Style (Style Description)'\n",
        "})\n",
        "df_subset = df_subset.fillna(\"\")\n",
        "# Display the result\n",
        "df_subset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "VmlJf_dZ2t3b",
        "outputId": "5afadb0e-6c25-40f3-92a2-f72f601a1956"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   ID      Style Point (Style Name)  \\\n",
              "0   2                       **A&E**   \n",
              "1   5    **aborigines, Aborigines**   \n",
              "2   6             **About, around**   \n",
              "3   7      **Absence, absenteeism**   \n",
              "4   8            **Accents, fadas**   \n",
              "5   9  **Accidents and collisions**   \n",
              "6  11                   **adapter**   \n",
              "\n",
              "                       Our Style (Style Description)  \\\n",
              "0  In body copy, use **emergency department**. Do...   \n",
              "1  Use aborigines when referring to indigenous po...   \n",
              "2  We use **around** to indicate a physical area....   \n",
              "3  **Absence** is not the same as **absenteeism**...   \n",
              "4  Use accents or fadas as required for Irish, Fr...   \n",
              "5  Use accident if nobody or nothing is at fault....   \n",
              "6  An adapter is somebody who adapts; it is not a...   \n",
              "\n",
              "                                       Correct usage  \\\n",
              "0                                                      \n",
              "1  The indigenous peoples of Taiwan, or Taiwan ab...   \n",
              "2  I got home from work at about 1am.\\n \\n \\n I d...   \n",
              "3  Absence makes the heart grow fonder.\\n \\n \\n T...   \n",
              "4  Tá Dáithí Ó Mathghamhna ag dul go dtí an crech...   \n",
              "5  The death was ruled a tragic accident.\\n \\n \\n...   \n",
              "6  She was known to go with the flow; she was an ...   \n",
              "\n",
              "                                     Incorrect usage  \\\n",
              "0                                                      \n",
              "1  Taiwan’s Aborigines have lived on the island f...   \n",
              "2  I got home around 1am.\\n \\n \\n I drove about t...   \n",
              "3  Half the staff caught covid leading to a high ...   \n",
              "4                                                      \n",
              "5  Gardaí are investigating the cause of the acci...   \n",
              "6  She was known to go with the flow; she was an ...   \n",
              "\n",
              "                                         Keywords  Type               Replace  \n",
              "0                                             A&E     1  Emergency Department  \n",
              "1               indigenous, aborigine, aborigines     2                        \n",
              "2                                   around, about     2                        \n",
              "3                            absence, absenteeism     2                        \n",
              "4                                  Not applicable     4                        \n",
              "5                                  Not applicable     3                        \n",
              "6  adapter, adaptor, adopt, adapt, adopts, adapts     2                        "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-130dd8d4-7a6e-45b2-933a-6302b4d3f222\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Style Point (Style Name)</th>\n",
              "      <th>Our Style (Style Description)</th>\n",
              "      <th>Correct usage</th>\n",
              "      <th>Incorrect usage</th>\n",
              "      <th>Keywords</th>\n",
              "      <th>Type</th>\n",
              "      <th>Replace</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>**A&amp;E**</td>\n",
              "      <td>In body copy, use **emergency department**. Do...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>A&amp;E</td>\n",
              "      <td>1</td>\n",
              "      <td>Emergency Department</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>**aborigines, Aborigines**</td>\n",
              "      <td>Use aborigines when referring to indigenous po...</td>\n",
              "      <td>The indigenous peoples of Taiwan, or Taiwan ab...</td>\n",
              "      <td>Taiwan’s Aborigines have lived on the island f...</td>\n",
              "      <td>indigenous, aborigine, aborigines</td>\n",
              "      <td>2</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>**About, around**</td>\n",
              "      <td>We use **around** to indicate a physical area....</td>\n",
              "      <td>I got home from work at about 1am.\\n \\n \\n I d...</td>\n",
              "      <td>I got home around 1am.\\n \\n \\n I drove about t...</td>\n",
              "      <td>around, about</td>\n",
              "      <td>2</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7</td>\n",
              "      <td>**Absence, absenteeism**</td>\n",
              "      <td>**Absence** is not the same as **absenteeism**...</td>\n",
              "      <td>Absence makes the heart grow fonder.\\n \\n \\n T...</td>\n",
              "      <td>Half the staff caught covid leading to a high ...</td>\n",
              "      <td>absence, absenteeism</td>\n",
              "      <td>2</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8</td>\n",
              "      <td>**Accents, fadas**</td>\n",
              "      <td>Use accents or fadas as required for Irish, Fr...</td>\n",
              "      <td>Tá Dáithí Ó Mathghamhna ag dul go dtí an crech...</td>\n",
              "      <td></td>\n",
              "      <td>Not applicable</td>\n",
              "      <td>4</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>9</td>\n",
              "      <td>**Accidents and collisions**</td>\n",
              "      <td>Use accident if nobody or nothing is at fault....</td>\n",
              "      <td>The death was ruled a tragic accident.\\n \\n \\n...</td>\n",
              "      <td>Gardaí are investigating the cause of the acci...</td>\n",
              "      <td>Not applicable</td>\n",
              "      <td>3</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>11</td>\n",
              "      <td>**adapter**</td>\n",
              "      <td>An adapter is somebody who adapts; it is not a...</td>\n",
              "      <td>She was known to go with the flow; she was an ...</td>\n",
              "      <td>She was known to go with the flow; she was an ...</td>\n",
              "      <td>adapter, adaptor, adopt, adapt, adopts, adapts</td>\n",
              "      <td>2</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-130dd8d4-7a6e-45b2-933a-6302b4d3f222')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-130dd8d4-7a6e-45b2-933a-6302b4d3f222 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-130dd8d4-7a6e-45b2-933a-6302b4d3f222');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-59aec128-dfb7-4f88-b36f-872323dfc321\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-59aec128-dfb7-4f88-b36f-872323dfc321')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-59aec128-dfb7-4f88-b36f-872323dfc321 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_b127e9a1-bb29-4965-9d70-fb51ad5e3c01\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_subset')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_b127e9a1-bb29-4965-9d70-fb51ad5e3c01 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_subset');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_subset",
              "summary": "{\n  \"name\": \"df_subset\",\n  \"rows\": 7,\n  \"fields\": [\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 2,\n        \"max\": 11,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          2,\n          5,\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Style Point (Style Name)\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"**A&E**\",\n          \"**aborigines, Aborigines**\",\n          \"**Accidents and collisions**\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Our Style (Style Description)\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"In body copy, use **emergency department**. Do not use A&E\",\n          \"Use aborigines when referring to indigenous populations, though our preference is for **indigenous peoples** . \\n \\n \\n Use Aborigines when referring to the indigenous peoples of Australia.\",\n          \"Use accident if nobody or nothing is at fault.\\n \\n \\n Cars collide with each other but not with stationary objects (they hit them)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Correct usage\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"\",\n          \"The indigenous peoples of Taiwan, or Taiwan aborigines, make up about 560,000 people.\",\n          \"The death was ruled a tragic accident.\\n \\n \\n The car hit a pedestrian.\\n \\n \\n The vans collided head-on.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Incorrect usage\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"\",\n          \"Taiwan\\u2019s Aborigines have lived on the island for thousands of years.\",\n          \"She was known to go with the flow; she was an adaptor.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Keywords\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"A&E\",\n          \"indigenous, aborigine, aborigines\",\n          \"adapter, adaptor, adopt, adapt, adopts, adapts\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Type\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 4,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          3,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Replace\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"\",\n          \"Emergency Department\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Ec_QfjUP7Kjj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### The Type of guideline defines how we identify it\n",
        "\n",
        "1 - is a simple search / replace - could be done without AI (Search for Keywords; suggested replacement from 'Replace' column\n",
        "\n",
        "2 - search using Keywords (checking each item in comma-delimited list) (not AI)\n",
        "\n",
        "3 - semantic meaning search using Pinecone dense vectors (RAG AI)\n",
        "\n",
        "4 - Always check this rule"
      ],
      "metadata": {
        "id": "B5fVOFhy7Pah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(HTML('''\n",
        "<style>\n",
        "     label {\n",
        "         display: block;\n",
        "         margin-bottom: 5px;\n",
        "         font-weight: bold;\n",
        "         width: 100%;\n",
        "     }\n",
        "     select, textarea {\n",
        "         width: 100%;\n",
        "         padding: 10px;\n",
        "         margin-bottom: 15px;\n",
        "         border: 1px solid #ccc;\n",
        "         border-radius: 4px;\n",
        "         font-size: 14px;\n",
        "         height: 100%;\n",
        "     }\n",
        "     button {\n",
        "         background-color: #4CAF50;\n",
        "         color: white;\n",
        "         padding: 10px 20px;\n",
        "         border: none;\n",
        "         border-radius: 4px;\n",
        "         cursor: pointer;\n",
        "         font-size: 16px;\n",
        "     }\n",
        "     button:hover {\n",
        "         background-color: #45a049;\n",
        "     }\n",
        " </style>\n",
        "'''))\n",
        "\n",
        "model_dropdown = widgets.Dropdown(\n",
        "    options=['gpt-4o-mini'],\n",
        "    value='gpt-4o-mini',\n",
        "    description='Model:',\n",
        "    layout=widgets.Layout(width='30%', height='50px')\n",
        ")\n",
        "\n",
        "# Sample text from an article for initial test\n",
        "\n",
        "input_text = widgets.Textarea(value='He easily adapts to the latest technology.\\nPeople run the 1,500m and take part in a 5,000m race. \\nHe was an early adopter of the new technology.\\nThe newspaper goes to press at 10:30 PM.\\nThe car collided with a pedestrian.\\nHis excellency, the archbishop was there',\n",
        "    placeholder='Type the input text here',\n",
        "    description='Article:',\n",
        "    layout=widgets.Layout(width='80%', height='375px')\n",
        ")\n",
        "\n",
        "output = widgets.Output()\n",
        "\n",
        "generate_button = widgets.Button(description=\"Generate Output\")\n",
        "\n",
        "\n",
        "def on_generate_button_click(b):\n",
        "    with output:\n",
        "        output.clear_output()\n",
        "        try:\n",
        "          generate_output(input_text.value, model_dropdown.value)\n",
        "        except AttributeError as e:\n",
        "          print(\"AttributeError:\", e)\n",
        "        except Exception as e:\n",
        "          print(\"An error occurred:\", e)\n",
        "\n"
      ],
      "metadata": {
        "id": "S_PF6JKzkvex",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "96c34ee2-9430-491d-bfe9-ff3e14fefdaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "     label {\n",
              "         display: block;\n",
              "         margin-bottom: 5px;\n",
              "         font-weight: bold;\n",
              "         width: 100%;\n",
              "     }\n",
              "     select, textarea {\n",
              "         width: 100%;\n",
              "         padding: 10px;\n",
              "         margin-bottom: 15px;\n",
              "         border: 1px solid #ccc;\n",
              "         border-radius: 4px;\n",
              "         font-size: 14px;\n",
              "         height: 100%;\n",
              "     }\n",
              "     button {\n",
              "         background-color: #4CAF50;\n",
              "         color: white;\n",
              "         padding: 10px 20px;\n",
              "         border: none;\n",
              "         border-radius: 4px;\n",
              "         cursor: pointer;\n",
              "         font-size: 16px;\n",
              "     }\n",
              "     button:hover {\n",
              "         background-color: #45a049;\n",
              "     }\n",
              " </style>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create pinecone index\n"
      ],
      "metadata": {
        "id": "J5eZDpRcqwk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pinecone\n",
        "\n",
        "PCApi = userdata.get('PINECONE_API_KEY')\n",
        "\n",
        "# Access the Pinecone API key from Colab secrets\n",
        "# PCApi = os.environ.get('PINECONE_API_KEY')\n",
        "if not PCApi:\n",
        "    raise ValueError(\"PINECONE_API_KEY is not set in the environment variables.\")"
      ],
      "metadata": {
        "id": "V2SEXMWK6GkT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pinecone = Pinecone(api_key=PCApi)\n",
        "\n",
        "cloud = os.environ.get('PINECONE_CLOUD') or 'aws'\n",
        "region = os.environ.get('PINECONE_REGION') or 'us-east-1'\n",
        "spec = ServerlessSpec(cloud=cloud, region=region)\n",
        "\n",
        "index_name = 'semantic-search-fast3'\n",
        "#pinecone.delete_index(index_name)\n",
        "\n",
        "pinecone.create_index(\n",
        "    name='semantic-search-fast3',\n",
        "    #dimension=1536,  # 1536 is the dimension used with text-embedding-ada-002 or 3072 for text-embedding-3-small (if used)\n",
        "    dimension=3072,  # 3072 is the dimension used with text-embedding-3-large\n",
        "    metric='dotproduct',\n",
        "    spec=spec\n",
        ")\n",
        "index = pinecone.Index('semantic-search-fast3')"
      ],
      "metadata": {
        "id": "Ly2Y82I2s4mf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "outputId": "35bd6fae-1d9d-4db7-face-524abb16913a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnauthorizedException",
          "evalue": "(401)\nReason: Unauthorized\nHTTP response headers: HTTPHeaderDict({'x-pinecone-api-version': '2024-04', 'X-Cloud-Trace-Context': '1406914e13f129a5c9f3616a1ed25c39', 'Date': 'Wed, 15 Jan 2025 12:22:50 GMT', 'Content-Type': 'text/html', 'Server': 'Google Frontend', 'Content-Length': '15', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\nHTTP response body: Invalid API Key\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnauthorizedException\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-87bad8f15f71>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#pinecone.delete_index(index_name)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m pinecone.create_index(\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'semantic-search-fast3'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m#dimension=1536,  # 1536 is the dimension used with text-embedding-ada-002 or 3072 for text-embedding-3-small (if used)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pinecone/control/pinecone.py\u001b[0m in \u001b[0;36mcreate_index\u001b[0;34m(self, name, dimension, spec, metric, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mapi_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate_index_request\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCreateIndexRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimension\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdimension\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mServerlessSpec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m             \u001b[0mapi_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate_index_request\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCreateIndexRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimension\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdimension\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPodSpec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mapi_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate_index_request\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCreateIndexRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimension\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdimension\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pinecone/core/client/api_client.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         \"\"\"\n\u001b[0;32m--> 771\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_http_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pinecone/core/client/api/manage_indexes_api.py\u001b[0m in \u001b[0;36m__create_index\u001b[0;34m(self, create_index_request, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'create_index_request'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0mcreate_index_request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_with_http_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         self.create_index = _Endpoint(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pinecone/core/client/api_client.py\u001b[0m in \u001b[0;36mcall_with_http_info\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'header'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Content-Type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mheader_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         return self.api_client.call_api(\n\u001b[0m\u001b[1;32m    834\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'endpoint_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'http_method'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pinecone/core/client/api_client.py\u001b[0m in \u001b[0;36mcall_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, async_req, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[1;32m    406\u001b[0m         \"\"\"\n\u001b[1;32m    407\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0masync_req\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m             return self.__call_api(resource_path, method,\n\u001b[0m\u001b[1;32m    409\u001b[0m                                    \u001b[0mpath_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m                                    \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpost_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pinecone/core/client/api_client.py\u001b[0m in \u001b[0;36m__call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mPineconeApiException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pinecone/core/client/api_client.py\u001b[0m in \u001b[0;36m__call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0;31m# perform request and return response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m             response_data = self.request(\n\u001b[0m\u001b[1;32m    196\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheader_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m                 \u001b[0mpost_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpost_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pinecone/core/client/api_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, query_params, headers, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    452\u001b[0m                                             body=body)\n\u001b[1;32m    453\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m             return self.rest_client.POST(url,\n\u001b[0m\u001b[1;32m    455\u001b[0m                                          \u001b[0mquery_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m                                          \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pinecone/core/client/rest.py\u001b[0m in \u001b[0;36mPOST\u001b[0;34m(self, url, headers, query_params, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    299\u001b[0m     def POST(self, url, headers=None, query_params=None, post_params=None,\n\u001b[1;32m    300\u001b[0m              body=None, _preload_content=True, _request_timeout=None):\n\u001b[0;32m--> 301\u001b[0;31m         return self.request(\"POST\", url,\n\u001b[0m\u001b[1;32m    302\u001b[0m                             \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m                             \u001b[0mquery_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pinecone/core/client/rest.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, query_params, headers, body, post_params, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m299\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m401\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mUnauthorizedException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_resp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m403\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnauthorizedException\u001b[0m: (401)\nReason: Unauthorized\nHTTP response headers: HTTPHeaderDict({'x-pinecone-api-version': '2024-04', 'X-Cloud-Trace-Context': '1406914e13f129a5c9f3616a1ed25c39', 'Date': 'Wed, 15 Jan 2025 12:22:50 GMT', 'Content-Type': 'text/html', 'Server': 'Google Frontend', 'Content-Length': '15', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\nHTTP response body: Invalid API Key\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare lists of rules and entries"
      ],
      "metadata": {
        "id": "0AKx9WECxMNO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "df['Style Point'] = df['Style Point'].str.replace('**', '', regex=False)\n",
        "\n",
        "# Replace null values in keywords with 'Our Style' column\n",
        "df['Our Style'].fillna(df['Keywords'], inplace=True)\n",
        "df['Our Style'].replace('', 'placeholder text', inplace=True)\n",
        "df['Our Style'].fillna('placeholder text', inplace=True)\n",
        "\n",
        "df_filtered = df[df[\"Type\"] == 3]\n",
        "\n",
        "\n",
        "ID_list = df_filtered[\"ID\"].tolist()\n",
        "type_list = df_filtered[\"Type\"].tolist()\n",
        "keywords_list = df_filtered[\"Keywords\"].tolist()\n",
        "\n",
        "rule_list = df_filtered.apply(\n",
        "    lambda row: (\n",
        "        row[\"Style Point\"] + ' ' +\n",
        "        row[\"Our Style\"] +\n",
        "        (' Examples of correct usage: ' + row[\"Correct usage\"] if pd.notna(row[\"Correct usage\"]) and row[\"Correct usage\"] != '' else '') +\n",
        "        (' Examples of incorrect usage: ' + row[\"Incorrect usage\"] if pd.notna(row[\"Incorrect usage\"]) and row[\"Incorrect usage\"] != '' else '')\n",
        "    ),\n",
        "    axis=1\n",
        ").tolist()\n",
        "\n",
        "#print(f\"rule_list: {rule_list}\")\n",
        "# TO REMOVE - Keep track of rule ids to check what is going into embeddings.\n",
        "rule_ids = df_filtered[\"ID\"].tolist()\n",
        "\n",
        "# Remove final , in csv of keywords if exists\n",
        "def clean_comma_delimited_list(myListString):\n",
        "  if myListString.endswith(','):\n",
        "      myListString = myListString[:-1]\n",
        "  return myListString\n",
        "\n",
        "def limit_rule_ids(matched_rule_ids):\n",
        "\n",
        "    # make a hard limit of rules in case too many are found\n",
        "    limit_rules_genai = 20\n",
        "\n",
        "    if len(matched_rule_ids) >= limit_rules_genai:\n",
        "\n",
        "        matched_rule_ids = matched_rule_ids[:limit_rules_genai]\n",
        "\n",
        "    rule_ids_comma_delimited_string = \",\".join(map(str, matched_rule_ids))\n",
        "    return rule_ids_comma_delimited_string\n"
      ],
      "metadata": {
        "id": "KR-b1vAes-R8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9988e357-261f-444f-bfa5-6e02762c08f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-45-bc3816b616f2>:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Our Style'].fillna(df['Keywords'], inplace=True)\n",
            "<ipython-input-45-bc3816b616f2>:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Our Style'].replace('', 'placeholder text', inplace=True)\n",
            "<ipython-input-45-bc3816b616f2>:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Our Style'].fillna('placeholder text', inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Narrow down rules from guideline to a subset to run in a prompt.\n",
        "\n",
        "*   More performant\n",
        "*   Less cost (fewer tokens)\n",
        "\n",
        "## Pinecone settings\n",
        "\n",
        "###### Setting the score needs experimentation.\n",
        "\n",
        "###### If too many false positive found, consider:\n",
        "\n",
        "*   increasing the score\n",
        "*  improving the comprehensibility of the guidelines found by pinecone search (in our case, type 3 rules)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kZsaeVKvxUuW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def narrow_down_rules(textToValidate):\n",
        "\n",
        "  top_k = 10  # Limit number of results to return by pinecone query to ensure efficiency.\n",
        "\n",
        "  matched_rule_ids_all = []\n",
        "  matched_rule_ids_string_search_with_ai = []\n",
        "  matched_rule_ids_dense = []\n",
        "  matched_rule_ids_always = []\n",
        "\n",
        "  for i in range(len(df)):\n",
        "      myType = df.loc[i, 'Type']\n",
        "      rule_id = df.loc[i, 'ID']\n",
        "      keyword_csv = df.loc[i, 'Keywords']\n",
        "      keyword_csv = clean_comma_delimited_list(keyword_csv)\n",
        "\n",
        "      # FIND TYPE 2 RULES - Do string search for rules with a list of keywords to match in the article\n",
        "\n",
        "      if myType == 2:\n",
        "          relevant_sentences = []\n",
        "          matched = False  # Reset matched for each rule\n",
        "\n",
        "          for keyword in keyword_csv.split(','):\n",
        "              keyword = keyword.strip().lower()\n",
        "\n",
        "              # find matches to keywords of complete words only\n",
        "              matched_sentences = [\n",
        "                sentence.strip() for sentence in textToValidate.split('.')\n",
        "                if (f\" {keyword} \" in f\" {sentence.lower()} \" or  # keyword in the middle\n",
        "                  sentence.lower().startswith(f\"{keyword} \") or  # keyword at the start\n",
        "                  sentence.lower().endswith(f\" {keyword}\"))      # keyword at the end\n",
        "              ]\n",
        "\n",
        "              if matched_sentences:\n",
        "                  matched = True\n",
        "                  myID = int(df.loc[i, 'ID'])\n",
        "                  myKeywords = df.loc[i, 'Keywords']\n",
        "                  relevant_sentences.extend(matched_sentences)\n",
        "                  break  # Stop checking further if a match is found within this rule\n",
        "          if matched:\n",
        "            sentenceCount = 0\n",
        "            for sentence in relevant_sentences:\n",
        "                sentenceCount += 1\n",
        "                print(f\"Found {myKeywords} in {sentenceCount} sentences, Rule ID: {myID}\")\n",
        "                print(f\"Sentence: '{sentence}'\")\n",
        "                if myID not in matched_rule_ids_string_search_with_ai:\n",
        "                  matched_rule_ids_string_search_with_ai.append(str(int(myID)))\n",
        "\n",
        "          # Convert ID array to strings - to match format of dense array\n",
        "          matched_rule_ids_string_search_with_ai = [str(item) for item in matched_rule_ids_string_search_with_ai]\n",
        "\n",
        "      # FIND TYPE 4 RULES\n",
        "\n",
        "      elif myType == 4:\n",
        "        myID = int(df.loc[i, 'ID'])\n",
        "        matched_rule_ids_always.append(str(int(myID)))\n",
        "\n",
        "  # FIND TYPE 3 RULES\n",
        "\n",
        "  # Generate embeddings a second time, for the article text\n",
        "  # (in order to query against the stored rule embeddings)\n",
        "\n",
        "  query_dense = get_embeddings([textToValidate])[0]\n",
        "\n",
        "  # ========================================================\n",
        "\n",
        "  # Calculate cost of embeddings creation for rule_list ...\n",
        "  encoder = tiktoken.encoding_for_model(\"text-embedding-3-large\")\n",
        "  embedding_tokens_article = len(encoder.encode(textToValidate))\n",
        "\n",
        "  # - for Open AI embeddings model\n",
        "\n",
        "  embedding_article_cost = calculate_token_usage_cost(embedding_tokens_article, text_embedding_3_large_tokens_cost_per_million)\n",
        "\n",
        "  print(f\"Embedding tokens used for article: {embedding_tokens_article}\")\n",
        "  print(f\"Cost for embeddings for article: ${embedding_article_cost:.6f}\")\n",
        "\n",
        "  # = for Pinecone\n",
        "\n",
        "  query_vectors = 1  # Number of query vectors (textToValidate)\n",
        "  read_units = query_vectors * (top_k / 10)  # 1 read unit per 10 results\n",
        "\n",
        "  pinecone_cost_query = calculate_pinecone_cost(read_units, 0, 0, 0, 0)  # Only read units\n",
        "  print(f\"Pinecone cost currently free on starter plan but estimate based on lowest rate for standard plan:\\n  Pinecone Cost for querying: ${pinecone_cost_query:.6f}\")\n",
        "\n",
        "  #1 Query the index with dense embedding\n",
        "  query_response = index.query(\n",
        "        top_k=top_k,\n",
        "        vector=query_dense,  # Running query on dense vector\n",
        "        include_metadata=True\n",
        "  )\n",
        "\n",
        "  for match in query_response['matches']:\n",
        "          keywords = match[\"metadata\"][\"keywords\"]\n",
        "          score = match[\"score\"]\n",
        "          myID = str(int(match[\"metadata\"][\"ID\"]))\n",
        "          myType = match[\"metadata\"][\"type\"]\n",
        "\n",
        "\n",
        "          print(\"myID\", myID, \" score:\", score, \"keywords:\", keywords)\n",
        "\n",
        "\n",
        "          if score > 0.28:  # Experiment with increasing/decreasing score to find more/less rules\n",
        "            matched_rule_ids_dense.append(str(int(myID)))\n",
        "\n",
        "\n",
        "  matched_rules_filtered = [item for item in matched_rule_ids_string_search_with_ai if item not in matched_rule_ids_dense]\n",
        "\n",
        "  matched_rule_ids_all = matched_rule_ids_string_search_with_ai + matched_rule_ids_dense + matched_rule_ids_always\n",
        "\n",
        "  print(\"Matched Rule IDs Type 2 - String search on keywords:\", matched_rule_ids_string_search_with_ai)\n",
        "\n",
        "  print(f\"Matched Rule IDs Type 3 - Meaning search on keywords - Pinecone: \", matched_rule_ids_dense)\n",
        "\n",
        "  print(\"Matched Rule IDs Type 4 - Always checked via prompt:\", matched_rule_ids_always)\n",
        "\n",
        "  print(\"All Matched Rule IDs:\", matched_rule_ids_all)\n",
        "\n",
        "  # Generate a formatted string of rules for matched_rule_ids_all\n",
        "  string_of_rules = \"\"\n",
        "  for rule_id in matched_rule_ids_all:\n",
        "        row = df.loc[df['ID'] == int(rule_id)]\n",
        "        if not row.empty:\n",
        "            rule_text = (\n",
        "                f\"Rule {row['ID'].values[0]}\\n\"\n",
        "                f\"{row['Style Point'].values[0]}\\n\"\n",
        "                f\"{row['Our Style'].values[0]}\\n\"\n",
        "            )\n",
        "            # Add correct and incorrect usage examples if available\n",
        "            if pd.notna(row['Correct usage'].values[0]):\n",
        "                rule_text += f\"This is correct usage:\\n{row['Correct usage'].values[0]}\\n\"\n",
        "            if pd.notna(row['Incorrect usage'].values[0]):\n",
        "                rule_text += f\"This is incorrect usage:\\n{row['Incorrect usage'].values[0]}\\n\"\n",
        "\n",
        "            # Append this rule text to the overall string with line breaks\n",
        "            string_of_rules += f\"{rule_text}\\n\\n\"\n",
        "\n",
        "  print(f\"=============\")\n",
        "  return matched_rule_ids_all, embedding_tokens_article, embedding_article_cost, string_of_rules;\n",
        "\n"
      ],
      "metadata": {
        "id": "Svzgab58nWAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate embeddings using OpenAI's embeddings models\n",
        "\n",
        "Our tests found text-embedding-3-large gave better results than text-embedding-ada-002 or text-embedding-3-small, from the Open AI suite of embedding models currently available"
      ],
      "metadata": {
        "id": "A9SSc3Urt92g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embeddings(rule_list):\n",
        "    response = openai.Embedding.create(\n",
        "        input=rule_list,\n",
        "        model=\"text-embedding-3-large\"\n",
        "    )\n",
        "    embeddings = [embedding['embedding'] for embedding in response['data']]\n",
        "\n",
        "    return embeddings\n",
        "\n",
        "# Generate embeddings the first time, from the rules, to store in pinecone\n",
        "embeddings = get_embeddings(rule_list)\n",
        "\n",
        "# Calculate costs for embeddings creation for rule_list\n",
        "\n",
        "# - for Open AI model\n",
        "encoder = tiktoken.encoding_for_model(\"text-embedding-3-large\")\n",
        "embedding_tokens_rule_list = sum([len(encoder.encode(text)) for text in rule_list])\n",
        "text_embedding_3_large_tokens_cost_per_million = 0.13\n",
        "embedding_rule_list_token_cost = calculate_token_usage_cost(embedding_tokens_rule_list, text_embedding_3_large_tokens_cost_per_million)\n",
        "\n",
        "# Print token and cost information\n",
        "print(f\"Embedding tokens used for rule_list: {embedding_tokens_rule_list}\")\n",
        "print(f\"Cost for embeddings for rule_list: ${embedding_rule_list_token_cost:.6f}\")\n",
        "\n",
        "# - for Pinecone\n",
        "vector_size_in_bytes = 3072 * 4  # 3072 dimensions, float32 (4 bytes)\n",
        "num_upsert_vectors = len(embeddings)  # Number of vectors stored\n",
        "\n",
        "write_units = num_upsert_vectors / 1000  # 1 write unit per 1000 vectors\n",
        "\n",
        "# Calculate Pinecone cost for storing and upserting vectors\n",
        "pinecone_cost_rules = calculate_pinecone_cost(0, write_units, storage_cost_per_gb, vector_size_in_bytes, num_upsert_vectors)\n",
        "print(f\"Pinecone Cost currently free on starter plan but estimate based on lowest rate for standard plan - for storing and upserting rules: ${pinecone_cost_rules:.6f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YPDsEkrMhArW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd52a48d-022c-43e2-b034-f7fd78920517"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding tokens used for rule_list: 335\n",
            "Cost for embeddings for rule_list: $0.000044\n",
            "Pinecone Cost currently free on starter plan but estimate based on lowest rate for standard plan - for storing and upserting rules: $0.000008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare records for upsert in Pinecone"
      ],
      "metadata": {
        "id": "1le_U_MGvVBu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "records = []\n",
        "for i in range(len(embeddings)):\n",
        "    ind_dic = {\n",
        "        'id': f'vec{i+1}',\n",
        "        'values': embeddings[i],\n",
        "        'metadata': {\n",
        "            'rule': rule_list[i],\n",
        "            'ID': ID_list[i],\n",
        "            'type': type_list[i],\n",
        "        }\n",
        "    }\n",
        "    records.append(ind_dic)\n",
        "\n",
        "\n",
        "index.upsert(vectors=records)"
      ],
      "metadata": {
        "id": "MpNzT2PevQtk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30e06fb5-9ca1-41a4-c29c-7357b451d9b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'upserted_count': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use function call to set the json output format of prompt"
      ],
      "metadata": {
        "id": "PI7FRXxgnobq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result_functions = [\n",
        "    {\n",
        "        'name': 'validate_article_compliance',\n",
        "        'description': 'Validate article compliance with rules',\n",
        "        'parameters': {\n",
        "            'type': 'object',\n",
        "            'properties': {\n",
        "                'isArticleCompliantWithAllRules': {\n",
        "                    'type': 'boolean',\n",
        "                    'description': 'Indicates whether the article complies with all rules.'\n",
        "                },\n",
        "                'issuesOfNonCompliance': {\n",
        "                    'type': 'array',\n",
        "                    'items': {\n",
        "                        'type': 'object',\n",
        "                        'properties': {\n",
        "                            'ruleID': {\n",
        "                                'type': 'string',\n",
        "                                'description': 'Rule ID'\n",
        "                            },\n",
        "                            'stylePoint': {\n",
        "                                'type': 'string',\n",
        "                                'description': 'Style Point'\n",
        "                            },\n",
        "                            'ourStyle': {\n",
        "                                'type': 'string',\n",
        "                                'description': 'Our Style'\n",
        "                            },\n",
        "                            'textWithProblem': {\n",
        "                                'type': 'string',\n",
        "                                'description': 'Text containing the compliance issue.'\n",
        "                            },\n",
        "                            'suggestedAlternative': {\n",
        "                                'type': 'string',\n",
        "                                'description': 'Suggested alternative text.'\n",
        "                            },\n",
        "                            'explanation': {\n",
        "                                'type': 'string',\n",
        "                                'description': 'Explanation of the issue.'\n",
        "                            }\n",
        "                        }\n",
        "                    },\n",
        "                    'description': 'List of compliance issues.'\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "]\n"
      ],
      "metadata": {
        "id": "o2EP1weNpJ44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run prompt using Open AI\n",
        "## the latest models got the best results from our tests"
      ],
      "metadata": {
        "id": "Vb76Wrt4v3_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_compliance_check(guideline, text, matched_rule_ids, model, embedding_tokens_article, embedding_article_cost, string_of_rules):\n",
        "\n",
        "    rule_ids_formatted_for_prompt = limit_rule_ids(matched_rule_ids)\n",
        "\n",
        "    print('matched_rule_ids', matched_rule_ids)\n",
        "\n",
        "\n",
        "    # Generate prompt preamble before listing all rules\n",
        "    prompt = f\"\"\"Here are the rules. \\n\\n\n",
        "        Go through rule IDs {string_of_rules} only) provided in the uploaded style guide (ignore all other rules), and in each case, state if the provided input text is compliant with each of the rules.\n",
        "        In each case, state if the provided input text is compliant with each of the following rules.\n",
        "        If the context is not found, do not apply the guideline, and state that the text is compliant.\n",
        "        If the context is not certain, ignore the guideline and state that the rule is compliant.\n",
        "        Provide an explanation in each case.\n",
        "        Return a json array as a result.\n",
        "        The json must have the format as stated in the function call\n",
        "        There should be one result per rule ID that is not compliant in one array.\n",
        "        Only the provided rules should be used and that any external information or assumptions should be excluded.\n",
        "        Then there should be one overall value of isArticleCompliantWithAllRules (true/false). When a ruleID is output in Json format it as an Integer\"\"\"\n",
        "\n",
        "    # Alternative prompt - also works\n",
        "    #prompt = f\"\"\"You are the editor-in-chief at an international news agency, tasked with revising and verifying all copy before publication.\n",
        "    #  Your responsibilities include:\n",
        "    #  Reading Text Inputs: Analyze each text input against established guidelines.\n",
        "    #  Go through rules  {string_of_rules}\n",
        "    #  Output Requirements:\n",
        "    #  Provide explanations for each non-compliant rule.\n",
        "    #  Return a JSON array with:\n",
        "    #  Each non-compliant rule ID.\n",
        "    #  A single overall value of isArticleCompliantWithAllRules (true/false).\"\"\"\n",
        "\n",
        "    # print(\"Generated Prompt:\\n\", prompt)\n",
        "\n",
        "    send_prompt = (\n",
        "        f\"{prompt}\\n\\n\"\n",
        "        f\"Guideline: {guideline}\\n\\n\"\n",
        "        f\"Text: {text}\\n\\n\"\n",
        "    )\n",
        "\n",
        "\n",
        "    start_time = time.time()\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=[{\"role\": \"user\", \"content\": send_prompt}],\n",
        "        temperature=0,\n",
        "        functions = result_functions,\n",
        "        function_call = 'auto'\n",
        "    )\n",
        "\n",
        "    # Get costs of tokens depending on model used\n",
        "    genai_input_tokens_cost_per_million, genai_output_tokens_cost_per_million = get_token_costs(model)\n",
        "\n",
        "    # Get the input tokens\n",
        "    usage = response['usage']\n",
        "    genAI_input_tokens = usage['prompt_tokens']\n",
        "    genAI_input_token_cost = calculate_token_usage_cost(genAI_input_tokens, genai_input_tokens_cost_per_million)\n",
        "    print(f\"GenAI Input tokens: {genAI_input_tokens} - cost this time: ${genAI_input_token_cost:.6f}\")\n",
        "\n",
        "    # Get the output tokens\n",
        "    genAI_output_tokens = usage['completion_tokens']\n",
        "    genAI_output_token_cost = calculate_token_usage_cost(genAI_output_tokens, genai_output_tokens_cost_per_million)\n",
        "    print(f\"GenAI Output tokens: {genAI_output_tokens} - cost this time: ${genAI_output_token_cost:.6f}\")\n",
        "\n",
        "    genAI_token_cost = genAI_input_token_cost + genAI_output_token_cost\n",
        "    print(f\"Total genAI cost this time: ${genAI_token_cost:.6f}\")\n",
        "\n",
        "    end_time = time.time()\n",
        "    encoder = tiktoken.encoding_for_model(model)\n",
        "    tokens = encoder.encode(send_prompt)\n",
        "\n",
        "    # cost true as of 2024\n",
        "    text_embedding_3_large_tokens_cost_per_million = 0.13\n",
        "\n",
        "    tokens_embedding = sum([len(encoder.encode(send_prompt)) for text in rule_list])\n",
        "    embedding_token_cost = calculate_token_usage_cost(tokens_embedding, text_embedding_3_large_tokens_cost_per_million)\n",
        "    print(f\"Embedding tokens used for rules: {tokens_embedding} - Cost this time: ${embedding_token_cost:.6f}\")\n",
        "\n",
        "    total_openAI_cost = embedding_token_cost + genAI_token_cost\n",
        "    print(f\"Total OpenAI cost: ${total_openAI_cost:.6f}\")\n",
        "    print(f\"Gen AI call time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "\n",
        "    json_response = '';\n",
        "\n",
        "    try:\n",
        "        json_response = json.loads(response.choices[0].message.get(\"function_call\", {}).get(\"arguments\", \"{}\"))\n",
        "        formatted_json = json.dumps(json_response, indent=2)\n",
        "    except json.JSONDecodeError:\n",
        "        formatted_json = \"Invalid JSON response or no function call arguments.\"\n",
        "\n",
        "    print('formatted_json', formatted_json)\n",
        "\n",
        "\n",
        "    return json_response, embedding_tokens_article, embedding_article_cost"
      ],
      "metadata": {
        "id": "rmPWbQ24wPKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compile rule to run in prompt from sheet columns\n",
        "### Format of rule generated from sheet columns\n",
        "### {Rule ID} {Style Point} {Our Style}\n",
        "### correct Usage: {List of correct usage examples}\n",
        "### incorrect Usage: {List of incorrect usage examples}\n"
      ],
      "metadata": {
        "id": "WfILL3McwWjW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_guideline_from_df(df):\n",
        "    guidelines = []\n",
        "    for i, row in df.iterrows():\n",
        "        parts = []  # List to hold the parts of the guideline\n",
        "\n",
        "        if pd.notna(row['ID']):\n",
        "            parts.append(f\"Rule {row['ID']}\")\n",
        "        if pd.notna(row['Style Point']):\n",
        "            parts.append(f\"{row['Style Point']}\")\n",
        "        if pd.notna(row['Our Style']):\n",
        "            parts.append(f\"{row['Our Style']}\")\n",
        "        if pd.notna(row['Correct usage']):\n",
        "            parts.append(f\"This type of usage is correct: {row['Correct usage']}\")\n",
        "        if pd.notna(row['Incorrect usage']):\n",
        "            parts.append(f\"This type of usage is incorrect: {row['Incorrect usage']}\")\n",
        "\n",
        "        # Join the parts with a newline, only if there are any parts to join\n",
        "        if parts:\n",
        "            guideline = \"\\n\".join(parts)\n",
        "            guidelines.append(guideline)\n",
        "\n",
        "    return \"\\n\\n\".join(guidelines)  # Separate each guideline by an extra newline\n"
      ],
      "metadata": {
        "id": "g9fapFVPwutl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate output when form button is clicked.\n",
        "## Output shows below the form in the grey area"
      ],
      "metadata": {
        "id": "KiM6nfd1w0YF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_output(example, model):\n",
        "\n",
        "    matched_rule_ids, embedding_tokens_article, embedding_article_cost, string_of_rules = narrow_down_rules(example)\n",
        "    guideline = generate_guideline_from_df(df)\n",
        "    response = get_compliance_check(guideline, example, matched_rule_ids, model, embedding_tokens_article, embedding_article_cost, string_of_rules)\n",
        "\n",
        "generate_button.on_click(on_generate_button_click)\n",
        "\n",
        "display(widgets.VBox([model_dropdown, input_text, generate_button, output]))\n",
        "\n",
        "class Document:\n",
        "    def __init__(self, page_content, metadata):\n",
        "        self.page_content = page_content\n",
        "        self.metadata = metadata"
      ],
      "metadata": {
        "id": "FVZnxqizuSIP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0bdd839d942249ee8e392c419707a6d2",
            "e49786e060464be2af51f65a262236c2",
            "158539c832e341c680336fd9f8858c8b",
            "90140fa876f94d1e875049f15e0502ec",
            "9c44bf616e3842dba678783cf260210c",
            "dfa4ae36950a41d8a3d05b0c8d2b540a",
            "5f9500dcbe7f4805824f0539616d8f7a",
            "ffdba4d4d822450fb6a7ddcb6bba5bb4",
            "53e3261c1f154288802961323f90b2c5",
            "c81e395aaea444ce970f24e6cd998149",
            "8c4914d640fd42fb904ef5884e8eea27",
            "b5575f0c87e24986bc885a823eba8e0d",
            "0d31c13bd1884d41b24831a66b396503"
          ]
        },
        "outputId": "850b3c24-63dc-4c44-f556-c3a0a0f1fd84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Dropdown(description='Model:', layout=Layout(height='50px', width='30%'), options=('gpt-4o-mini…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0bdd839d942249ee8e392c419707a6d2"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}